{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2b7d45-6914-4fab-89f4-9e65fa9dd125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.14 s (started: 2022-07-22 04:31:52 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers.core import Activation\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, LSTM, Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d689197d-0ec3-45ba-937d-b9c3d3050d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 691 ms (started: 2022-07-22 04:31:54 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Train - Dev - Test Generation\n",
    "train_raw = pd.read_csv('./dataset/train.csv').drop('Unnamed: 0', axis=1)\n",
    "dev_raw = pd.read_csv('./dataset/dev.csv').drop('Unnamed: 0', axis=1)\n",
    "test1_raw = pd.read_csv('./dataset/test1.csv').drop('Unnamed: 0', axis=1)\n",
    "test2_raw = pd.read_csv('./dataset/test2.csv').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "train_X = train_raw.iloc[:, :-1]\n",
    "dev_X = dev_raw.iloc[:, :-1]\n",
    "test1_X = test1_raw.iloc[:, :-1]\n",
    "test2_X = test2_raw.iloc[:, :-1]\n",
    "train_Y = train_raw.iloc[:, -1]\n",
    "dev_Y = dev_raw.iloc[:, -1]\n",
    "test1_Y = test1_raw.iloc[:, -1]\n",
    "test2_Y = test2_raw.iloc[:, -1]\n",
    "\n",
    "\n",
    "# data sampling\n",
    "STEP = 20\n",
    "#num_list = [STEP*i for i in range(int(1117500/STEP))]\n",
    "\n",
    "_train_X = np.asarray(train_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_dev_X = np.asarray(dev_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_test1_X = np.asarray(test1_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_test2_X = np.asarray(test2_X).reshape((int(1117500/STEP), 20, 1))\n",
    "\n",
    "_train_Y = np.asarray(train_Y).reshape(int(1117500/STEP), 1)\n",
    "_dev_Y = np.asarray(dev_Y).reshape(int(1117500/STEP), 1)\n",
    "_test1_Y = np.asarray(test1_Y).reshape(int(1117500/STEP), 1)\n",
    "_test2_Y = np.asarray(test2_Y).reshape(int(1117500/STEP), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab821d8d-8257-41c3-b22f-ec257da5f053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 25)                2700      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,726\n",
      "Trainable params: 2,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 622 ms (started: 2022-07-22 04:31:54 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 04:31:54.773658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:54.776323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:54.776451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:54.776712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-22 04:31:54.777211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:54.777342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:54.777454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:55.091660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:55.091813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:55.091930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 04:31:55.092029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22310 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def double_tanh(x):\n",
    "    return (K.tanh(x) * 2)\n",
    "\n",
    "#get_custom_objects().update({'double_tanh':Activation(double_tanh)})\n",
    "\n",
    "# Model Generation\n",
    "model = Sequential()\n",
    "#check https://machinelearningmastery.com/use-weight-regularization-lstm-networks-time-series-forecasting/\n",
    "model.add(LSTM(25, input_shape=(20,1), dropout=0.0, kernel_regularizer=l1_l2(0.00,0.00), bias_regularizer=l1_l2(0.00,0.00)))\n",
    "model.add(Dense(1, activation=double_tanh))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "#, kernel_regularizer=l1_l2(0,0.1), bias_regularizer=l1_l2(0,0.1),\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39eef9a-351b-459a-bdc5-f497d1bd450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./lstm_only_models/LSTM_only_new_api/epoch1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./lstm_only_models/LSTM_only_new_api/epoch1/assets\n",
      "2022-07-22 04:31:58.646050: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/112 [========>.....................] - ETA: 0s - loss: 0.2262 - mse: 0.2262 - mae: 0.3973 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 04:31:59.069066: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 2s 3ms/step - loss: 0.2010 - mse: 0.2010 - mae: 0.3731\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1898 - mse: 0.1898 - mae: 0.3627\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2843 - mse: 0.2843 - mae: 0.4345\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2778 - mse: 0.2778 - mae: 0.4311\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3282 - mse: 0.3282 - mae: 0.4672\n",
      "train set score : mse - 0.1898219734430313 / mae - 0.3627184331417084\n",
      "dev set score : mse - 0.284330278635025 / mae - 0.4344899654388428\n",
      "test1 set score : mse - 0.2777898907661438 / mae - 0.4310569167137146\n",
      "test2 set score : mse - 0.32823866605758667 / mae - 0.46721434593200684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./lstm_only_models/LSTM_only_new_api/epoch2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./lstm_only_models/LSTM_only_new_api/epoch2/assets\n",
      "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f2b4c289a90> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2017 - mse: 0.2017 - mae: 0.3739\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1900 - mse: 0.1900 - mae: 0.3640\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2818 - mse: 0.2818 - mae: 0.4335\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2759 - mse: 0.2759 - mae: 0.4306\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3256 - mse: 0.3256 - mae: 0.4663\n",
      "train set score : mse - 0.18995918333530426 / mae - 0.3639538586139679\n",
      "dev set score : mse - 0.28179770708084106 / mae - 0.4335481822490692\n",
      "test1 set score : mse - 0.27593299746513367 / mae - 0.43062466382980347\n",
      "test2 set score : mse - 0.3256468176841736 / mae - 0.4662596583366394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./lstm_only_models/LSTM_only_new_api/epoch3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./lstm_only_models/LSTM_only_new_api/epoch3/assets\n",
      "WARNING:absl:<keras.saving.saved_model.load.Dense object at 0x7f2aec402fa0> has the same name 'Dense' as a built-in Keras object. Consider renaming <class 'keras.saving.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2004 - mse: 0.2004 - mae: 0.3725\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.1898 - mse: 0.1898 - mae: 0.3628\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.2842 - mse: 0.2842 - mae: 0.4345\n",
      " 232/1747 [==>...........................] - ETA: 2s - loss: 0.2579 - mse: 0.2579 - mae: 0.4118"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m score_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(_train_X, _train_Y)\n\u001b[1;32m     38\u001b[0m score_dev \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(_dev_X, _dev_Y)\n\u001b[0;32m---> 39\u001b[0m score_test1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_test1_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_test1_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m score_test2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(_test2_X, _test2_Y)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain set score : mse - \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(score_train[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m / mae - \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(score_train[\u001b[38;5;241m2\u001b[39m]))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1755\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1756\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1758\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2689\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2685\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2686\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments supplied to `defun`-generated functions must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2687\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashable.  Original error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2689\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2691\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/polymorphism/function_cache.py:121\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, key, use_function_subtyping)\u001b[0m\n\u001b[1;32m    119\u001b[0m dispatch_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_table\u001b[38;5;241m.\u001b[39mdispatch(key)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_primary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdispatch_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/polymorphism/function_cache.py:86\u001b[0m, in \u001b[0;36mFunctionCacheKey.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, FunctionCacheKey):\n\u001b[1;32m     83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_context \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39mcall_context \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_signature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_signature\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py:130\u001b[0m, in \u001b[0;36mOrderedCollection.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, trace\u001b[38;5;241m.\u001b[39mTraceType):\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shallow_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    131\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39mcomponents\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py:101\u001b[0m, in \u001b[0;36mOrderedCollection._shallow_equal\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_shallow_equal\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m     99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(other, OrderedCollection) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    100\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_type \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39mcollection_type \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m           \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45.4 s (started: 2022-07-22 04:31:55 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Model\n",
    "model_scores = {}\n",
    "Reg = False\n",
    "d = 'LSTM_only_new_api'\n",
    "\n",
    "if Reg :\n",
    "    d += '_with_reg'\n",
    "\n",
    "epoch_num=1\n",
    "max_epoch = 3500\n",
    "for _ in range(max_epoch):\n",
    "\n",
    "    # train the model\n",
    "    dir_ = './lstm_only_models/'+d\n",
    "    file_list = os.listdir(dir_)\n",
    "    if len(file_list) != 0 :\n",
    "        epoch_num = len(file_list) + 1\n",
    "        recent_model_name = 'epoch'+str(epoch_num-1)\n",
    "        filepath = './lstm_only_models/' + d + '/' + recent_model_name\n",
    "        # custom_objects = {\"double_tanh\": double_tanh}\n",
    "        # with keras.utils.custom_object_scope(custom_objects):\n",
    "        model = load_model(filepath)\n",
    "\n",
    "    filepath = './lstm_only_models/' + d + '/epoch'+str(epoch_num)\n",
    "\n",
    "    # checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "    model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True)\n",
    "    model.save(filepath)\n",
    "    \n",
    "    #callbacks_list = [checkpoint]\n",
    "    #if len(callbacks_list) == 0:\n",
    "    #    model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True)\n",
    "    #else:\n",
    "    #    model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "    # test the model\n",
    "    score_train = model.evaluate(_train_X, _train_Y)\n",
    "    score_dev = model.evaluate(_dev_X, _dev_Y)\n",
    "    score_test1 = model.evaluate(_test1_X, _test1_Y)\n",
    "    score_test2 = model.evaluate(_test2_X, _test2_Y)\n",
    "\n",
    "    print('train set score : mse - ' + str(score_train[1]) +' / mae - ' + str(score_train[2]))\n",
    "    print('dev set score : mse - ' + str(score_dev[1]) +' / mae - ' + str(score_dev[2]))\n",
    "    print('test1 set score : mse - ' + str(score_test1[1]) +' / mae - ' + str(score_test1[2]))\n",
    "    print('test2 set score : mse - ' + str(score_test2[1]) +' / mae - ' + str(score_test2[2]))\n",
    "#.history['mean_squared_error'][0]\n",
    "    # get former score data\n",
    "    df = pd.read_csv(\"./lstm_only_scores/\"+d+\".csv\")\n",
    "    train_mse = list(df['TRAIN_MSE'])\n",
    "    dev_mse = list(df['DEV_MSE'])\n",
    "    test1_mse = list(df['TEST1_MSE'])\n",
    "    test2_mse = list(df['TEST2_MSE'])\n",
    "\n",
    "    train_mae = list(df['TRAIN_MAE'])\n",
    "    dev_mae = list(df['DEV_MAE'])\n",
    "    test1_mae = list(df['TEST1_MAE'])\n",
    "    test2_mae = list(df['TEST2_MAE'])\n",
    "\n",
    "    # append new data\n",
    "    train_mse.append(score_train[1])\n",
    "    dev_mse.append(score_dev[1])\n",
    "    test1_mse.append(score_test1[1])\n",
    "    test2_mse.append(score_test2[1])\n",
    "\n",
    "    train_mae.append(score_train[2])\n",
    "    dev_mae.append(score_dev[2])\n",
    "    test1_mae.append(score_test1[2])\n",
    "    test2_mae.append(score_test2[2])\n",
    "\n",
    "    # organize newly created score dataset\n",
    "    model_scores['TRAIN_MSE'] = train_mse\n",
    "    model_scores['DEV_MSE'] = dev_mse\n",
    "    model_scores['TEST1_MSE'] = test1_mse\n",
    "    model_scores['TEST2_MSE'] = test2_mse\n",
    "\n",
    "    model_scores['TRAIN_MAE'] = train_mae\n",
    "    model_scores['DEV_MAE'] = dev_mae\n",
    "    model_scores['TEST1_MAE'] = test1_mae\n",
    "    model_scores['TEST2_MAE'] = test2_mae\n",
    "    \n",
    "    # save newly created score dataset\n",
    "    model_scores_df = pd.DataFrame(model_scores)\n",
    "    model_scores_df.to_csv(\"./lstm_only_scores/\"+d+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17e5e9-882b-4adf-90e2-2c010aadd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
