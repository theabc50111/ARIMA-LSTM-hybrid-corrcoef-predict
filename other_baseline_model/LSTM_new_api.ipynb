{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2b7d45-6914-4fab-89f4-9e65fa9dd125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.12 s (started: 2022-10-19 01:33:10 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers.core import Activation\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, LSTM, Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "err_log_handler = logging.FileHandler(filename=\"./models/arima_train_err_log.txt\", mode='a')\n",
    "err_logger = logging.getLogger(\"arima_train_err\")\n",
    "err_logger.addHandler(err_log_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeff40e-d0b9-46ba-ab97-9b782de39af1",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3faba9-e37c-4c4a-93e4-e3bb0c4597ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 437 µs (started: 2022-10-19 01:33:13 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# setting of output files\n",
    "save_raw_corr_data = True\n",
    "save_train_info_arima_resid_data = True\n",
    "# data implement setting\n",
    "data_implement = \"sp500_20082017\"  # tw50|sp500_20082017|sp500_19972007|tetuan_power\n",
    "# train set setting\n",
    "items_setting = \"train\"  # train|all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe208abf-0ea9-49b2-b8ba-334d745fde61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:===== len(train_set): 150, len(all_set): 445, len(test_set): 296 =====\n",
      "INFO:root:===== len(train set): 150 =====\n",
      "INFO:root:===== file_name basis:sp500_20082017_train =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99 ms (started: 2022-10-19 01:33:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# data loading & implement setting\n",
    "dataset_path = Path(\"../dataset/\")\n",
    "if data_implement == \"tw50\":\n",
    "    file_name = Path(\"tw50_hold_20082018_adj_close_pre.csv\")\n",
    "    train_set = ['萬海_adj_close', '豐泰_adj_close', '友達_adj_close', '欣興_adj_close', '台塑化_adj_close', '和泰車_adj_close', '元大金_adj_close', '南電_adj_close', '台塑_adj_close', '統一超_adj_close', '台泥_adj_close', '瑞昱_adj_close', '彰銀_adj_close', '富邦金_adj_close', '研華_adj_close', '中鋼_adj_close', '鴻海_adj_close', '台新金_adj_close', '遠傳_adj_close', '南亞_adj_close', '台達電_adj_close', '台灣大_adj_close', '台化_adj_close', '聯詠_adj_close', '廣達_adj_close', '聯發科_adj_close', '台積電_adj_close', '統一_adj_close', '中信金_adj_close', '長榮_adj_close']\n",
    "elif data_implement == \"sp500_19972007\":\n",
    "    file_name = Path(\"sp500_hold_19972007_adj_close_pre.csv\")\n",
    "    train_set = ['PXD', 'WAT', 'LH', 'AMGN', 'AOS', 'EFX', 'NEM', 'CTAS', 'MAT', 'VLO', 'APH', 'ADM', 'MLM', 'BK', 'NOV', 'BDX', 'RRC', 'IVZ', 'ED', 'SBUX', 'CI', 'ZION', 'COO', 'FDX', 'GLW', 'GPC', 'HPQ', 'ADI', 'AMG', 'MTB', 'YUM', 'SYK', 'KMX', 'AME', 'BMY', 'KMB', 'JPM', 'AET', 'DLTR', 'MGM', 'FL', 'HD', 'CLX', 'OKE', 'WMB', 'IFF', 'CMS', 'MMC', 'REG', 'ES', 'ITW', 'VRTX', 'QCOM', 'MSI', 'NKTR', 'AMAT', 'BWA', 'ESRX', 'TXT', 'VNO', 'WDC', 'PVH', 'NOC', 'PCAR', 'NSC', 'PHM', 'LUV', 'HUM', 'SPG', 'SJM', 'ABT', 'ALK', 'TAP', 'CAT', 'TMO', 'AES', 'MRK', 'RMD', 'MKC', 'HIG', 'DE', 'ATVI', 'O', 'UNM', 'VMC', 'CMA', 'RHI', 'RE', 'FMC', 'MU', 'CB', 'LNT', 'GE', 'SNA', 'LLY', 'LEN', 'MAA', 'OMC', 'F', 'APA', 'CDNS', 'SLG', 'HP', 'SHW', 'AFL', 'STT', 'PAYX', 'AIG']\n",
    "elif data_implement in [\"sp500_20082017\", \"paper_eva_1\", \"paper_eva_2\", \"paper_eva_3\", \"paper_eva_4\", \"paper_eva_5\"]:\n",
    "    file_name = Path(\"stock08_price.csv\")\n",
    "    train_set = ['CELG', 'PXD', 'WAT', 'LH', 'AMGN', 'AOS', 'EFX', 'CRM', 'NEM', 'JNPR', 'LB', 'CTAS', 'MAT', 'MDLZ', 'VLO', 'APH', 'ADM', 'MLM', 'BK', 'NOV', 'BDX', 'RRC', 'IVZ', 'ED', 'SBUX', 'GRMN', 'CI', 'ZION', 'COO', 'TIF', 'RHT', 'FDX', 'LLL', 'GLW', 'GPN', 'IPGP', 'GPC', 'HPQ', 'ADI', 'AMG', 'MTB', 'YUM', 'SYK', 'KMX', 'AME', 'AAP', 'DAL', 'A', 'MON', 'BRK', 'BMY', 'KMB', 'JPM', 'CCI', 'AET', 'DLTR', 'MGM', 'FL', 'HD', 'CLX', 'OKE', 'UPS', 'WMB', 'IFF', 'CMS', 'ARNC', 'VIAB', 'MMC', 'REG', 'ES', 'ITW', 'NDAQ', 'AIZ', 'VRTX', 'CTL', 'QCOM', 'MSI', 'NKTR', 'AMAT', 'BWA', 'ESRX', 'TXT', 'EXR', 'VNO', 'BBT', 'WDC', 'UAL', 'PVH', 'NOC', 'PCAR', 'NSC', 'UAA', 'FFIV', 'PHM', 'LUV', 'HUM', 'SPG', 'SJM', 'ABT', 'CMG', 'ALK', 'ULTA', 'TMK', 'TAP', 'SCG', 'CAT', 'TMO', 'AES', 'MRK', 'RMD', 'MKC', 'WU', 'ACN', 'HIG', 'TEL', 'DE', 'ATVI', 'O', 'UNM', 'VMC', 'ETFC', 'CMA', 'NRG', 'RHI', 'RE', 'FMC', 'MU', 'CB', 'LNT', 'GE', 'CBS', 'ALGN', 'SNA', 'LLY', 'LEN', 'MAA', 'OMC', 'F', 'APA', 'CDNS', 'SLG', 'HP', 'XLNX', 'SHW', 'AFL', 'STT', 'PAYX', 'AIG', 'FOX', 'MA']\n",
    "elif data_implement == \"tetuan_power\":\n",
    "    file_name = Path(\"Tetuan City power consumption_pre.csv\")\n",
    "    train_set = [\"Temperature\", \"Humidity\", \"Wind Speed\", \"general diffuse flows\", \"diffuse flows\", \"Zone 1 Power Consumption\", \"Zone 2 Power Consumption\", \"Zone 3 Power Consumption\"]\n",
    "\n",
    "dataset_df = pd.read_csv(dataset_path/file_name)\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns.values[1:])  # all data\n",
    "test_set = [p for p in all_set if p not in train_set]  # all data - train data\n",
    "logging.info(f\"===== len(train_set): {len(train_set)}, len(all_set): {len(all_set)}, len(test_set): {len(test_set)} =====\")\n",
    "\n",
    "# train set setting\n",
    "if items_setting == \"all\":\n",
    "    items_set = all_set\n",
    "    output_set_name = \"_all\"\n",
    "elif items_setting == \"train\":\n",
    "    items_set = train_set\n",
    "    output_set_name = \"_train\"\n",
    "train_info = {\"tw50\": {\"items\":items_set, \"file_name\": \"tw50_20082017\"},\n",
    "              \"sp500_19972007\": {\"items\":items_set, \"file_name\": f\"sp500_19972007\"},\n",
    "              \"sp500_20082017\": {\"items\": items_set, \"file_name\": f\"sp500_20082017\"},\n",
    "              \"tetuan_power\": {\"items\": items_set, \"file_name\":  f\"tetuan_power\"}}\n",
    "items_implement = train_info[data_implement]['items']\n",
    "logging.info(f\"===== len(train set): {len(items_implement)} =====\")\n",
    "\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = train_info[data_implement]['file_name'] + output_set_name\n",
    "logging.info(f\"===== file_name basis:{output_file_name} =====\")\n",
    "\n",
    "# display(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9739c702-6558-45cc-b2ba-3fa3db2e1107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 338 ms (started: 2022-10-19 01:33:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def gen_data_corr(items: list, corr_ind: list) -> \"pd.DataFrame\":\n",
    "    tmp_corr = dataset_df[items[0]].rolling(window=100).corr(dataset_df[items[1]])\n",
    "    tmp_corr = tmp_corr.iloc[corr_ind].values\n",
    "    data_df = pd.DataFrame(tmp_corr.reshape(-1, 24), dtype=\"float32\")\n",
    "    ind = [f\"{items[0]} & {items[1]}_{i}\" for i in range(0, 100, 20)]\n",
    "    data_df.index = ind\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def gen_train_data(items: list, corr_ind: list, save_file: bool = False)-> \"four pd.DataFrame\":\n",
    "    train_df = pd.DataFrame(dtype=\"float32\")\n",
    "    dev_df = pd.DataFrame(dtype=\"float32\")\n",
    "    test1_df = pd.DataFrame(dtype=\"float32\")\n",
    "    test2_df = pd.DataFrame(dtype=\"float32\")\n",
    "\n",
    "    for pair in tqdm(combinations(items, 2)):\n",
    "        data_df = gen_data_corr([pair[0], pair[1]], corr_ind=corr_ind)\n",
    "        data_split = {'train': [0, 21], 'dev': [1, 22], 'test1': [2, 23], 'test2': [3, 24]}\n",
    "        train_df = pd.concat([train_df, data_df.iloc[:, 0:21]])\n",
    "        dev_df = pd.concat([dev_df, data_df.iloc[:, 1:22]])\n",
    "        test1_df = pd.concat([test1_df, data_df.iloc[:, 2:23]])\n",
    "        test2_df = pd.concat([test2_df, data_df.iloc[:, 3:24]])\n",
    "\n",
    "    if save_file:\n",
    "        before_arima_data_path = dataset_path/f\"{output_file_name}_before_arima\"\n",
    "        before_arima_data_path.mkdir(parents=True, exist_ok=True)\n",
    "        train_df.to_csv(before_arima_data_path/f\"{output_file_name}_train.csv\")\n",
    "        dev_df.to_csv(before_arima_data_path/f\"{output_file_name}_dev.csv\")\n",
    "        test1_df.to_csv(before_arima_data_path/f\"{output_file_name}_test1.csv\")\n",
    "        test2_df.to_csv(before_arima_data_path/f\"{output_file_name}_test2.csv\")\n",
    "\n",
    "    return train_df, dev_df, test1_df, test2_df\n",
    "\n",
    "\n",
    "before_arima_data_path = dataset_path/f\"{output_file_name}_before_arima\"\n",
    "train_df = before_arima_data_path/f\"{output_file_name}_train.csv\"\n",
    "dev_df = before_arima_data_path/f\"{output_file_name}_dev.csv\"\n",
    "test1_df = before_arima_data_path/f\"{output_file_name}_test1.csv\"\n",
    "test2_df = before_arima_data_path/f\"{output_file_name}_test2.csv\"\n",
    "if train_df.exists() and dev_df.exists() and test1_df.exists() and test2_df.exists():\n",
    "    corr_datasets = (pd.read_csv(train_df), pd.read_csv(dev_df), pd.read_csv(test1_df), pd.read_csv(test2_df))\n",
    "else:\n",
    "    corr_ind = list(range(99, 2400, 100))  + list(range(99+20, 2500, 100)) + list(range(99+40, 2500, 100)) + list(range(99+60, 2500, 100)) + list(range(99+80, 2500, 100))\n",
    "    corr_datasets = gen_train_data(items_implement, corr_ind, save_file = save_raw_corr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d39ce16-363f-4c1a-b58d-860ff296027e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CELG &amp; PXD_0</th>\n",
       "      <td>0.590280</td>\n",
       "      <td>0.063858</td>\n",
       "      <td>0.679183</td>\n",
       "      <td>0.199338</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.364170</td>\n",
       "      <td>0.438221</td>\n",
       "      <td>-0.794414</td>\n",
       "      <td>-0.515353</td>\n",
       "      <td>0.241255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903754</td>\n",
       "      <td>0.868264</td>\n",
       "      <td>0.494260</td>\n",
       "      <td>0.452813</td>\n",
       "      <td>-0.375800</td>\n",
       "      <td>-0.197114</td>\n",
       "      <td>-0.677816</td>\n",
       "      <td>-0.395864</td>\n",
       "      <td>-0.315340</td>\n",
       "      <td>-0.010655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELG &amp; PXD_20</th>\n",
       "      <td>0.438420</td>\n",
       "      <td>0.652749</td>\n",
       "      <td>0.352477</td>\n",
       "      <td>0.622226</td>\n",
       "      <td>0.615217</td>\n",
       "      <td>-0.240156</td>\n",
       "      <td>0.782224</td>\n",
       "      <td>-0.790989</td>\n",
       "      <td>0.313710</td>\n",
       "      <td>0.517477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.888502</td>\n",
       "      <td>0.687713</td>\n",
       "      <td>-0.074147</td>\n",
       "      <td>-0.087164</td>\n",
       "      <td>-0.607093</td>\n",
       "      <td>-0.368695</td>\n",
       "      <td>-0.741116</td>\n",
       "      <td>-0.188775</td>\n",
       "      <td>0.150085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELG &amp; PXD_40</th>\n",
       "      <td>0.328918</td>\n",
       "      <td>0.867458</td>\n",
       "      <td>-0.488062</td>\n",
       "      <td>0.574526</td>\n",
       "      <td>0.539969</td>\n",
       "      <td>-0.448536</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>-0.423448</td>\n",
       "      <td>0.407719</td>\n",
       "      <td>0.686462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861398</td>\n",
       "      <td>0.608115</td>\n",
       "      <td>0.845183</td>\n",
       "      <td>-0.344867</td>\n",
       "      <td>0.662313</td>\n",
       "      <td>-0.718643</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>-0.628298</td>\n",
       "      <td>0.390711</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELG &amp; PXD_60</th>\n",
       "      <td>-0.382146</td>\n",
       "      <td>0.859304</td>\n",
       "      <td>-0.561882</td>\n",
       "      <td>0.604127</td>\n",
       "      <td>0.722692</td>\n",
       "      <td>-0.113043</td>\n",
       "      <td>0.675429</td>\n",
       "      <td>-0.338822</td>\n",
       "      <td>-0.117613</td>\n",
       "      <td>0.831165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605477</td>\n",
       "      <td>0.494596</td>\n",
       "      <td>0.906395</td>\n",
       "      <td>-0.330687</td>\n",
       "      <td>0.891210</td>\n",
       "      <td>-0.826001</td>\n",
       "      <td>-0.203952</td>\n",
       "      <td>-0.360892</td>\n",
       "      <td>0.522659</td>\n",
       "      <td>0.245915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELG &amp; PXD_80</th>\n",
       "      <td>-0.593003</td>\n",
       "      <td>0.726890</td>\n",
       "      <td>-0.314456</td>\n",
       "      <td>0.439548</td>\n",
       "      <td>0.674778</td>\n",
       "      <td>0.283974</td>\n",
       "      <td>-0.246503</td>\n",
       "      <td>-0.538679</td>\n",
       "      <td>0.131311</td>\n",
       "      <td>0.832004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783975</td>\n",
       "      <td>0.266232</td>\n",
       "      <td>0.873553</td>\n",
       "      <td>-0.172410</td>\n",
       "      <td>0.523424</td>\n",
       "      <td>-0.810981</td>\n",
       "      <td>-0.056530</td>\n",
       "      <td>-0.066425</td>\n",
       "      <td>0.146766</td>\n",
       "      <td>0.451478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOX &amp; MA_0</th>\n",
       "      <td>-0.098180</td>\n",
       "      <td>0.917817</td>\n",
       "      <td>0.071451</td>\n",
       "      <td>0.595682</td>\n",
       "      <td>0.844499</td>\n",
       "      <td>0.395403</td>\n",
       "      <td>0.425420</td>\n",
       "      <td>0.368931</td>\n",
       "      <td>-0.337017</td>\n",
       "      <td>0.751782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767827</td>\n",
       "      <td>0.911805</td>\n",
       "      <td>0.880740</td>\n",
       "      <td>0.579875</td>\n",
       "      <td>0.543719</td>\n",
       "      <td>0.172596</td>\n",
       "      <td>0.669962</td>\n",
       "      <td>-0.239215</td>\n",
       "      <td>0.755595</td>\n",
       "      <td>0.742628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOX &amp; MA_20</th>\n",
       "      <td>-0.368111</td>\n",
       "      <td>0.937390</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>0.771566</td>\n",
       "      <td>0.850320</td>\n",
       "      <td>0.710853</td>\n",
       "      <td>0.747234</td>\n",
       "      <td>0.502675</td>\n",
       "      <td>-0.560923</td>\n",
       "      <td>0.607262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726629</td>\n",
       "      <td>0.889275</td>\n",
       "      <td>0.903055</td>\n",
       "      <td>0.407239</td>\n",
       "      <td>0.093362</td>\n",
       "      <td>0.494885</td>\n",
       "      <td>0.287612</td>\n",
       "      <td>-0.457826</td>\n",
       "      <td>0.804776</td>\n",
       "      <td>0.921419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOX &amp; MA_40</th>\n",
       "      <td>-0.167918</td>\n",
       "      <td>0.945463</td>\n",
       "      <td>0.243556</td>\n",
       "      <td>0.921268</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.888777</td>\n",
       "      <td>0.786345</td>\n",
       "      <td>0.769699</td>\n",
       "      <td>-0.418527</td>\n",
       "      <td>0.597815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785604</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.899782</td>\n",
       "      <td>-0.145309</td>\n",
       "      <td>0.314542</td>\n",
       "      <td>0.367583</td>\n",
       "      <td>0.133061</td>\n",
       "      <td>0.208245</td>\n",
       "      <td>0.839307</td>\n",
       "      <td>0.908114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOX &amp; MA_60</th>\n",
       "      <td>0.242583</td>\n",
       "      <td>0.937526</td>\n",
       "      <td>0.563173</td>\n",
       "      <td>0.951715</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.900770</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.734702</td>\n",
       "      <td>-0.149538</td>\n",
       "      <td>0.623108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854680</td>\n",
       "      <td>0.790261</td>\n",
       "      <td>0.928971</td>\n",
       "      <td>-0.094710</td>\n",
       "      <td>0.413759</td>\n",
       "      <td>0.690577</td>\n",
       "      <td>0.118558</td>\n",
       "      <td>0.487566</td>\n",
       "      <td>0.847068</td>\n",
       "      <td>0.760944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOX &amp; MA_80</th>\n",
       "      <td>0.802539</td>\n",
       "      <td>0.833362</td>\n",
       "      <td>0.684904</td>\n",
       "      <td>0.943243</td>\n",
       "      <td>0.413954</td>\n",
       "      <td>0.825214</td>\n",
       "      <td>0.344984</td>\n",
       "      <td>0.164792</td>\n",
       "      <td>0.509582</td>\n",
       "      <td>0.618142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879099</td>\n",
       "      <td>0.810770</td>\n",
       "      <td>0.910152</td>\n",
       "      <td>0.435101</td>\n",
       "      <td>0.516283</td>\n",
       "      <td>0.710131</td>\n",
       "      <td>0.265259</td>\n",
       "      <td>0.566952</td>\n",
       "      <td>0.775728</td>\n",
       "      <td>0.308790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55875 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5  \\\n",
       "Unnamed: 0                                                                  \n",
       "CELG & PXD_0   0.590280  0.063858  0.679183  0.199338  0.310183  0.364170   \n",
       "CELG & PXD_20  0.438420  0.652749  0.352477  0.622226  0.615217 -0.240156   \n",
       "CELG & PXD_40  0.328918  0.867458 -0.488062  0.574526  0.539969 -0.448536   \n",
       "CELG & PXD_60 -0.382146  0.859304 -0.561882  0.604127  0.722692 -0.113043   \n",
       "CELG & PXD_80 -0.593003  0.726890 -0.314456  0.439548  0.674778  0.283974   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "FOX & MA_0    -0.098180  0.917817  0.071451  0.595682  0.844499  0.395403   \n",
       "FOX & MA_20   -0.368111  0.937390  0.008614  0.771566  0.850320  0.710853   \n",
       "FOX & MA_40   -0.167918  0.945463  0.243556  0.921268  0.632534  0.888777   \n",
       "FOX & MA_60    0.242583  0.937526  0.563173  0.951715  0.386957  0.900770   \n",
       "FOX & MA_80    0.802539  0.833362  0.684904  0.943243  0.413954  0.825214   \n",
       "\n",
       "                      6         7         8         9  ...        11  \\\n",
       "Unnamed: 0                                             ...             \n",
       "CELG & PXD_0   0.438221 -0.794414 -0.515353  0.241255  ...  0.903754   \n",
       "CELG & PXD_20  0.782224 -0.790989  0.313710  0.517477  ...  0.922857   \n",
       "CELG & PXD_40  0.788591 -0.423448  0.407719  0.686462  ...  0.861398   \n",
       "CELG & PXD_60  0.675429 -0.338822 -0.117613  0.831165  ...  0.605477   \n",
       "CELG & PXD_80 -0.246503 -0.538679  0.131311  0.832004  ...  0.783975   \n",
       "...                 ...       ...       ...       ...  ...       ...   \n",
       "FOX & MA_0     0.425420  0.368931 -0.337017  0.751782  ...  0.767827   \n",
       "FOX & MA_20    0.747234  0.502675 -0.560923  0.607262  ...  0.726629   \n",
       "FOX & MA_40    0.786345  0.769699 -0.418527  0.597815  ...  0.785604   \n",
       "FOX & MA_60    0.693917  0.734702 -0.149538  0.623108  ...  0.854680   \n",
       "FOX & MA_80    0.344984  0.164792  0.509582  0.618142  ...  0.879099   \n",
       "\n",
       "                     12        13        14        15        16        17  \\\n",
       "Unnamed: 0                                                                  \n",
       "CELG & PXD_0   0.868264  0.494260  0.452813 -0.375800 -0.197114 -0.677816   \n",
       "CELG & PXD_20  0.888502  0.687713 -0.074147 -0.087164 -0.607093 -0.368695   \n",
       "CELG & PXD_40  0.608115  0.845183 -0.344867  0.662313 -0.718643  0.119225   \n",
       "CELG & PXD_60  0.494596  0.906395 -0.330687  0.891210 -0.826001 -0.203952   \n",
       "CELG & PXD_80  0.266232  0.873553 -0.172410  0.523424 -0.810981 -0.056530   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "FOX & MA_0     0.911805  0.880740  0.579875  0.543719  0.172596  0.669962   \n",
       "FOX & MA_20    0.889275  0.903055  0.407239  0.093362  0.494885  0.287612   \n",
       "FOX & MA_40    0.843400  0.899782 -0.145309  0.314542  0.367583  0.133061   \n",
       "FOX & MA_60    0.790261  0.928971 -0.094710  0.413759  0.690577  0.118558   \n",
       "FOX & MA_80    0.810770  0.910152  0.435101  0.516283  0.710131  0.265259   \n",
       "\n",
       "                     18        19        20  \n",
       "Unnamed: 0                                   \n",
       "CELG & PXD_0  -0.395864 -0.315340 -0.010655  \n",
       "CELG & PXD_20 -0.741116 -0.188775  0.150085  \n",
       "CELG & PXD_40 -0.628298  0.390711  0.147500  \n",
       "CELG & PXD_60 -0.360892  0.522659  0.245915  \n",
       "CELG & PXD_80 -0.066425  0.146766  0.451478  \n",
       "...                 ...       ...       ...  \n",
       "FOX & MA_0    -0.239215  0.755595  0.742628  \n",
       "FOX & MA_20   -0.457826  0.804776  0.921419  \n",
       "FOX & MA_40    0.208245  0.839307  0.908114  \n",
       "FOX & MA_60    0.487566  0.847068  0.760944  \n",
       "FOX & MA_80    0.566952  0.775728  0.308790  \n",
       "\n",
       "[55875 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.5 ms (started: 2022-10-19 01:34:49 +00:00)\n"
     ]
    }
   ],
   "source": [
    "corr_datasets[0].set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689197d-0ec3-45ba-937d-b9c3d3050d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Dev - Test Generation\n",
    "train_raw = corr_datasets[0].set_index(\"Unnamed: 0\")\n",
    "dev_raw = corr_datasets[1].set_index(\"Unnamed: 0\")\n",
    "test1_raw = corr_datasets[2].set_index(\"Unnamed: 0\")\n",
    "test2_raw = corr_datasets[3].set_index(\"Unnamed: 0\")\n",
    "\n",
    "\n",
    "lstm_train_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_train.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_train_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_train.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_dev_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_dev.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_dev_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_dev.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_test1_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test1.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_test1_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test1.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_test2_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test2.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_test2_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test2.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "\n",
    "train_X = train_raw.iloc[:, :-1]\n",
    "dev_X = dev_raw.iloc[:, :-1]\n",
    "test1_X = test1_raw.iloc[:, :-1]\n",
    "test2_X = test2_raw.iloc[:, :-1]\n",
    "train_Y = train_raw.iloc[:, -1]\n",
    "dev_Y = dev_raw.iloc[:, -1]\n",
    "test1_Y = test1_raw.iloc[:, -1]\n",
    "test2_Y = test2_raw.iloc[:, -1]\n",
    "\n",
    "\n",
    "# data sampling\n",
    "STEP = 20\n",
    "#num_list = [STEP*i for i in range(int(1117500/STEP))]\n",
    "\n",
    "_train_X = np.asarray(train_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_dev_X = np.asarray(dev_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_test1_X = np.asarray(test1_X).reshape((int(1117500/STEP), 20, 1))\n",
    "_test2_X = np.asarray(test2_X).reshape((int(1117500/STEP), 20, 1))\n",
    "\n",
    "_train_Y = np.asarray(train_Y).reshape(int(1117500/STEP), 1)\n",
    "_dev_Y = np.asarray(dev_Y).reshape(int(1117500/STEP), 1)\n",
    "_test1_Y = np.asarray(test1_Y).reshape(int(1117500/STEP), 1)\n",
    "_test2_Y = np.asarray(test2_Y).reshape(int(1117500/STEP), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab821d8d-8257-41c3-b22f-ec257da5f053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def double_tanh(x):\n",
    "    return (K.tanh(x) * 2)\n",
    "\n",
    "#get_custom_objects().update({'double_tanh':Activation(double_tanh)})\n",
    "\n",
    "# Model Generation\n",
    "model = Sequential()\n",
    "#check https://machinelearningmastery.com/use-weight-regularization-lstm-networks-time-series-forecasting/\n",
    "model.add(LSTM(25, input_shape=(20,1), dropout=0.0, kernel_regularizer=l1_l2(0.00,0.00), bias_regularizer=l1_l2(0.00,0.00)))\n",
    "model.add(Dense(1, activation=double_tanh))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "#, kernel_regularizer=l1_l2(0,0.1), bias_regularizer=l1_l2(0,0.1),\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39eef9a-351b-459a-bdc5-f497d1bd450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Model\n",
    "model_scores = {}\n",
    "Reg = False\n",
    "d = 'LSTM_only_new_api'\n",
    "\n",
    "if Reg :\n",
    "    d += '_with_reg'\n",
    "\n",
    "epoch_num=1\n",
    "max_epoch = 3500\n",
    "for _ in range(max_epoch):\n",
    "\n",
    "    # train the model\n",
    "    dir_ = './lstm_only_models/'+d\n",
    "    file_list = os.listdir(dir_)\n",
    "    if len(file_list) != 0 :\n",
    "        epoch_num = len(file_list) + 1\n",
    "        recent_model_name = 'epoch'+str(epoch_num-1)\n",
    "        filepath = './lstm_only_models/' + d + '/' + recent_model_name\n",
    "        # custom_objects = {\"double_tanh\": double_tanh}\n",
    "        # with keras.utils.custom_object_scope(custom_objects):\n",
    "        model = load_model(filepath)\n",
    "\n",
    "    filepath = './lstm_only_models/' + d + '/epoch'+str(epoch_num)\n",
    "\n",
    "    # checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "    model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True)\n",
    "    model.save(filepath)\n",
    "    \n",
    "    #callbacks_list = [checkpoint]\n",
    "    #if len(callbacks_list) == 0:\n",
    "    #    model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True)\n",
    "    #else:\n",
    "    #    model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "    # test the model\n",
    "    score_train = model.evaluate(_train_X, _train_Y)\n",
    "    score_dev = model.evaluate(_dev_X, _dev_Y)\n",
    "    score_test1 = model.evaluate(_test1_X, _test1_Y)\n",
    "    score_test2 = model.evaluate(_test2_X, _test2_Y)\n",
    "\n",
    "    print('train set score : mse - ' + str(score_train[1]) +' / mae - ' + str(score_train[2]))\n",
    "    print('dev set score : mse - ' + str(score_dev[1]) +' / mae - ' + str(score_dev[2]))\n",
    "    print('test1 set score : mse - ' + str(score_test1[1]) +' / mae - ' + str(score_test1[2]))\n",
    "    print('test2 set score : mse - ' + str(score_test2[1]) +' / mae - ' + str(score_test2[2]))\n",
    "#.history['mean_squared_error'][0]\n",
    "    # get former score data\n",
    "    df = pd.read_csv(\"./lstm_only_scores/\"+d+\".csv\")\n",
    "    train_mse = list(df['TRAIN_MSE'])\n",
    "    dev_mse = list(df['DEV_MSE'])\n",
    "    test1_mse = list(df['TEST1_MSE'])\n",
    "    test2_mse = list(df['TEST2_MSE'])\n",
    "\n",
    "    train_mae = list(df['TRAIN_MAE'])\n",
    "    dev_mae = list(df['DEV_MAE'])\n",
    "    test1_mae = list(df['TEST1_MAE'])\n",
    "    test2_mae = list(df['TEST2_MAE'])\n",
    "\n",
    "    # append new data\n",
    "    train_mse.append(score_train[1])\n",
    "    dev_mse.append(score_dev[1])\n",
    "    test1_mse.append(score_test1[1])\n",
    "    test2_mse.append(score_test2[1])\n",
    "\n",
    "    train_mae.append(score_train[2])\n",
    "    dev_mae.append(score_dev[2])\n",
    "    test1_mae.append(score_test1[2])\n",
    "    test2_mae.append(score_test2[2])\n",
    "\n",
    "    # organize newly created score dataset\n",
    "    model_scores['TRAIN_MSE'] = train_mse\n",
    "    model_scores['DEV_MSE'] = dev_mse\n",
    "    model_scores['TEST1_MSE'] = test1_mse\n",
    "    model_scores['TEST2_MSE'] = test2_mse\n",
    "\n",
    "    model_scores['TRAIN_MAE'] = train_mae\n",
    "    model_scores['DEV_MAE'] = dev_mae\n",
    "    model_scores['TEST1_MAE'] = test1_mae\n",
    "    model_scores['TEST2_MAE'] = test2_mae\n",
    "    \n",
    "    # save newly created score dataset\n",
    "    model_scores_df = pd.DataFrame(model_scores)\n",
    "    model_scores_df.to_csv(\"./lstm_only_scores/\"+d+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17e5e9-882b-4adf-90e2-2c010aadd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
