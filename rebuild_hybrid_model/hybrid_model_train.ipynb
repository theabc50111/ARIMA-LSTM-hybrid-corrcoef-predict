{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41660f84-97c9-4162-a708-f601b3b7a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.83 s (started: 2022-09-22 11:58:22 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from pmdarima.arima import ARIMA, auto_arima\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "err_log_handler = logging.FileHandler(filename=\"./models/arima_train_err_log.txt\", mode='a')\n",
    "err_logger = logging.getLogger(\"arima_train_err\")\n",
    "err_logger.addHandler(err_log_handler)\n",
    "\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on --ignore E501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a012b1-6376-486e-b5dd-93c76929fc3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167474f5-dd41-487c-a140-54d699e47621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pycodestyle:5:80: E501 line too long (84 > 79 characters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 461 µs (started: 2022-09-22 11:58:24 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# setting of output files\n",
    "save_raw_corr_data = True\n",
    "save_train_info_arima_resid_data = True\n",
    "# data implement setting\n",
    "data_implement = \"sp500_20082017\"  # tw50|sp500_20082017|sp500_19972007|tetuan_power\n",
    "# train set setting\n",
    "items_setting = \"train\"  # train|all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec99233-f96e-42c6-acc0-123e2ab6ceb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:===== len(train_set): 150, len(all_set): 445, len(test_set): 296 =====\n",
      "INFO:root:===== len(train set): 150 =====\n",
      "INFO:root:===== file_name basis:sp500_20082017_train =====\n",
      "INFO:pycodestyle:5:80: E501 line too long (507 > 79 characters)\n",
      "INFO:pycodestyle:8:80: E501 line too long (769 > 79 characters)\n",
      "INFO:pycodestyle:9:80: E501 line too long (117 > 79 characters)\n",
      "INFO:pycodestyle:11:80: E501 line too long (1071 > 79 characters)\n",
      "INFO:pycodestyle:14:80: E501 line too long (183 > 79 characters)\n",
      "INFO:pycodestyle:20:80: E501 line too long (123 > 79 characters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 105 ms (started: 2022-09-22 11:58:24 +00:00)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycodestyle_magic.py:46\u001b[0m, in \u001b[0;36mVarWatcher.auto_run_pycodestyle\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_run_pycodestyle\u001b[39m(\u001b[38;5;28mself\u001b[39m, result):\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mpycodestyle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_cell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror_before_exec:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError before execution: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m result\u001b[38;5;241m.\u001b[39merror_before_exec)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycodestyle_magic.py:175\u001b[0m, in \u001b[0;36mpycodestyle\u001b[0;34m(line, cell, auto)\u001b[0m\n\u001b[1;32m    170\u001b[0m stdout \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mgetvalue()\u001b[38;5;241m.\u001b[39msplitlines()   \n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m stdout:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m#logger.info(line)     \u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# on windows drive path also contains :\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     line, col, error \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:] \n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# do not subtract 1 for line for %%pycodestyle, inc pre py3.6 string\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auto:\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# data loading & implement setting\n",
    "dataset_path = Path(\"../dataset/\")\n",
    "if data_implement == \"tw50\":\n",
    "    file_name = Path(\"tw50_hold_20082018_adj_close_pre.csv\")\n",
    "    train_set = ['萬海_adj_close', '豐泰_adj_close', '友達_adj_close', '欣興_adj_close', '台塑化_adj_close', '和泰車_adj_close', '元大金_adj_close', '南電_adj_close', '台塑_adj_close', '統一超_adj_close', '台泥_adj_close', '瑞昱_adj_close', '彰銀_adj_close', '富邦金_adj_close', '研華_adj_close', '中鋼_adj_close', '鴻海_adj_close', '台新金_adj_close', '遠傳_adj_close', '南亞_adj_close', '台達電_adj_close', '台灣大_adj_close', '台化_adj_close', '聯詠_adj_close', '廣達_adj_close', '聯發科_adj_close', '台積電_adj_close', '統一_adj_close', '中信金_adj_close', '長榮_adj_close']\n",
    "elif data_implement == \"sp500_19972007\":\n",
    "    file_name = Path(\"sp500_hold_19972007_adj_close_pre.csv\")\n",
    "    train_set = ['PXD', 'WAT', 'LH', 'AMGN', 'AOS', 'EFX', 'NEM', 'CTAS', 'MAT', 'VLO', 'APH', 'ADM', 'MLM', 'BK', 'NOV', 'BDX', 'RRC', 'IVZ', 'ED', 'SBUX', 'CI', 'ZION', 'COO', 'FDX', 'GLW', 'GPC', 'HPQ', 'ADI', 'AMG', 'MTB', 'YUM', 'SYK', 'KMX', 'AME', 'BMY', 'KMB', 'JPM', 'AET', 'DLTR', 'MGM', 'FL', 'HD', 'CLX', 'OKE', 'WMB', 'IFF', 'CMS', 'MMC', 'REG', 'ES', 'ITW', 'VRTX', 'QCOM', 'MSI', 'NKTR', 'AMAT', 'BWA', 'ESRX', 'TXT', 'VNO', 'WDC', 'PVH', 'NOC', 'PCAR', 'NSC', 'PHM', 'LUV', 'HUM', 'SPG', 'SJM', 'ABT', 'ALK', 'TAP', 'CAT', 'TMO', 'AES', 'MRK', 'RMD', 'MKC', 'HIG', 'DE', 'ATVI', 'O', 'UNM', 'VMC', 'CMA', 'RHI', 'RE', 'FMC', 'MU', 'CB', 'LNT', 'GE', 'SNA', 'LLY', 'LEN', 'MAA', 'OMC', 'F', 'APA', 'CDNS', 'SLG', 'HP', 'SHW', 'AFL', 'STT', 'PAYX', 'AIG']\n",
    "elif data_implement in [\"sp500_20082017\", \"paper_eva_1\", \"paper_eva_2\", \"paper_eva_3\", \"paper_eva_4\", \"paper_eva_5\"]:\n",
    "    file_name = Path(\"stock08_price.csv\")\n",
    "    train_set = ['CELG', 'PXD', 'WAT', 'LH', 'AMGN', 'AOS', 'EFX', 'CRM', 'NEM', 'JNPR', 'LB', 'CTAS', 'MAT', 'MDLZ', 'VLO', 'APH', 'ADM', 'MLM', 'BK', 'NOV', 'BDX', 'RRC', 'IVZ', 'ED', 'SBUX', 'GRMN', 'CI', 'ZION', 'COO', 'TIF', 'RHT', 'FDX', 'LLL', 'GLW', 'GPN', 'IPGP', 'GPC', 'HPQ', 'ADI', 'AMG', 'MTB', 'YUM', 'SYK', 'KMX', 'AME', 'AAP', 'DAL', 'A', 'MON', 'BRK', 'BMY', 'KMB', 'JPM', 'CCI', 'AET', 'DLTR', 'MGM', 'FL', 'HD', 'CLX', 'OKE', 'UPS', 'WMB', 'IFF', 'CMS', 'ARNC', 'VIAB', 'MMC', 'REG', 'ES', 'ITW', 'NDAQ', 'AIZ', 'VRTX', 'CTL', 'QCOM', 'MSI', 'NKTR', 'AMAT', 'BWA', 'ESRX', 'TXT', 'EXR', 'VNO', 'BBT', 'WDC', 'UAL', 'PVH', 'NOC', 'PCAR', 'NSC', 'UAA', 'FFIV', 'PHM', 'LUV', 'HUM', 'SPG', 'SJM', 'ABT', 'CMG', 'ALK', 'ULTA', 'TMK', 'TAP', 'SCG', 'CAT', 'TMO', 'AES', 'MRK', 'RMD', 'MKC', 'WU', 'ACN', 'HIG', 'TEL', 'DE', 'ATVI', 'O', 'UNM', 'VMC', 'ETFC', 'CMA', 'NRG', 'RHI', 'RE', 'FMC', 'MU', 'CB', 'LNT', 'GE', 'CBS', 'ALGN', 'SNA', 'LLY', 'LEN', 'MAA', 'OMC', 'F', 'APA', 'CDNS', 'SLG', 'HP', 'XLNX', 'SHW', 'AFL', 'STT', 'PAYX', 'AIG', 'FOX', 'MA']\n",
    "elif data_implement == \"tetuan_power\":\n",
    "    file_name = Path(\"Tetuan City power consumption_pre.csv\")\n",
    "    train_set = [\"Temperature\", \"Humidity\", \"Wind Speed\", \"general diffuse flows\", \"diffuse flows\", \"Zone 1 Power Consumption\", \"Zone 2 Power Consumption\", \"Zone 3 Power Consumption\"]\n",
    "\n",
    "dataset_df = pd.read_csv(dataset_path/file_name)\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns.values[1:])  # all data\n",
    "test_set = [p for p in all_set if p not in train_set]  # all data - train data\n",
    "logging.info(f\"===== len(train_set): {len(train_set)}, len(all_set): {len(all_set)}, len(test_set): {len(test_set)} =====\")\n",
    "\n",
    "# train set setting\n",
    "if items_setting == \"all\":\n",
    "    items_set = all_set\n",
    "    output_set_name = \"_all\"\n",
    "elif items_setting == \"train\":\n",
    "    items_set = train_set\n",
    "    output_set_name = \"_train\"\n",
    "train_info = {\"tw50\": {\"items\":items_set, \"file_name\": \"tw50_20082017\"},\n",
    "              \"sp500_19972007\": {\"items\":items_set, \"file_name\": f\"sp500_19972007\"},\n",
    "              \"sp500_20082017\": {\"items\": items_set, \"file_name\": f\"sp500_20082017\"},\n",
    "              \"tetuan_power\": {\"items\": items_set, \"file_name\":  f\"tetuan_power\"}}\n",
    "items_implement = train_info[data_implement]['items']\n",
    "logging.info(f\"===== len(train set): {len(items_implement)} =====\")\n",
    "\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = train_info[data_implement]['file_name'] + output_set_name\n",
    "logging.info(f\"===== file_name basis:{output_file_name} =====\")\n",
    "\n",
    "# display(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7765e10-2944-4621-b62f-6602a573387f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Unnamed: 0         0         1         2         3         4  \\\n",
       " 0       CELG & PXD_0  0.590280  0.063858  0.679183  0.199338  0.310183   \n",
       " 1      CELG & PXD_20  0.438420  0.652749  0.352477  0.622226  0.615217   \n",
       " 2      CELG & PXD_40  0.328918  0.867458 -0.488062  0.574526  0.539969   \n",
       " 3      CELG & PXD_60 -0.382146  0.859304 -0.561882  0.604127  0.722692   \n",
       " 4      CELG & PXD_80 -0.593003  0.726890 -0.314456  0.439548  0.674778   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 55870     FOX & MA_0 -0.098180  0.917817  0.071451  0.595682  0.844499   \n",
       " 55871    FOX & MA_20 -0.368111  0.937390  0.008614  0.771566  0.850320   \n",
       " 55872    FOX & MA_40 -0.167918  0.945463  0.243556  0.921268  0.632534   \n",
       " 55873    FOX & MA_60  0.242583  0.937526  0.563173  0.951715  0.386957   \n",
       " 55874    FOX & MA_80  0.802539  0.833362  0.684904  0.943243  0.413954   \n",
       " \n",
       "               5         6         7         8  ...        11        12  \\\n",
       " 0      0.364170  0.438221 -0.794414 -0.515353  ...  0.903754  0.868264   \n",
       " 1     -0.240156  0.782224 -0.790989  0.313710  ...  0.922857  0.888502   \n",
       " 2     -0.448536  0.788591 -0.423448  0.407719  ...  0.861398  0.608115   \n",
       " 3     -0.113043  0.675429 -0.338822 -0.117613  ...  0.605477  0.494596   \n",
       " 4      0.283974 -0.246503 -0.538679  0.131311  ...  0.783975  0.266232   \n",
       " ...         ...       ...       ...       ...  ...       ...       ...   \n",
       " 55870  0.395403  0.425420  0.368931 -0.337017  ...  0.767827  0.911805   \n",
       " 55871  0.710853  0.747234  0.502675 -0.560923  ...  0.726629  0.889275   \n",
       " 55872  0.888777  0.786345  0.769699 -0.418527  ...  0.785604  0.843400   \n",
       " 55873  0.900770  0.693917  0.734702 -0.149538  ...  0.854680  0.790261   \n",
       " 55874  0.825214  0.344984  0.164792  0.509582  ...  0.879099  0.810770   \n",
       " \n",
       "              13        14        15        16        17        18        19  \\\n",
       " 0      0.494260  0.452813 -0.375800 -0.197114 -0.677816 -0.395864 -0.315340   \n",
       " 1      0.687713 -0.074147 -0.087164 -0.607093 -0.368695 -0.741116 -0.188775   \n",
       " 2      0.845183 -0.344867  0.662313 -0.718643  0.119225 -0.628298  0.390711   \n",
       " 3      0.906395 -0.330687  0.891210 -0.826001 -0.203952 -0.360892  0.522659   \n",
       " 4      0.873553 -0.172410  0.523424 -0.810981 -0.056530 -0.066425  0.146766   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 55870  0.880740  0.579875  0.543719  0.172596  0.669962 -0.239215  0.755595   \n",
       " 55871  0.903055  0.407239  0.093362  0.494885  0.287612 -0.457826  0.804776   \n",
       " 55872  0.899782 -0.145309  0.314542  0.367583  0.133061  0.208245  0.839307   \n",
       " 55873  0.928971 -0.094710  0.413759  0.690577  0.118558  0.487566  0.847068   \n",
       " 55874  0.910152  0.435101  0.516283  0.710131  0.265259  0.566952  0.775728   \n",
       " \n",
       "              20  \n",
       " 0     -0.010655  \n",
       " 1      0.150085  \n",
       " 2      0.147500  \n",
       " 3      0.245915  \n",
       " 4      0.451478  \n",
       " ...         ...  \n",
       " 55870  0.742628  \n",
       " 55871  0.921419  \n",
       " 55872  0.908114  \n",
       " 55873  0.760944  \n",
       " 55874  0.308790  \n",
       " \n",
       " [55875 rows x 22 columns],\n",
       "           Unnamed: 0         1         2         3         4         5  \\\n",
       " 0       CELG & PXD_0  0.063858  0.679183  0.199338  0.310183  0.364170   \n",
       " 1      CELG & PXD_20  0.652749  0.352477  0.622226  0.615217 -0.240156   \n",
       " 2      CELG & PXD_40  0.867458 -0.488062  0.574526  0.539969 -0.448536   \n",
       " 3      CELG & PXD_60  0.859304 -0.561882  0.604127  0.722692 -0.113043   \n",
       " 4      CELG & PXD_80  0.726890 -0.314456  0.439548  0.674778  0.283974   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 55870     FOX & MA_0  0.917817  0.071451  0.595682  0.844499  0.395403   \n",
       " 55871    FOX & MA_20  0.937390  0.008614  0.771566  0.850320  0.710853   \n",
       " 55872    FOX & MA_40  0.945463  0.243556  0.921268  0.632534  0.888777   \n",
       " 55873    FOX & MA_60  0.937526  0.563173  0.951715  0.386957  0.900770   \n",
       " 55874    FOX & MA_80  0.833362  0.684904  0.943243  0.413954  0.825214   \n",
       " \n",
       "               6         7         8         9  ...        12        13  \\\n",
       " 0      0.438221 -0.794414 -0.515353  0.241255  ...  0.868264  0.494260   \n",
       " 1      0.782224 -0.790989  0.313710  0.517477  ...  0.888502  0.687713   \n",
       " 2      0.788591 -0.423448  0.407719  0.686462  ...  0.608115  0.845183   \n",
       " 3      0.675429 -0.338822 -0.117613  0.831165  ...  0.494596  0.906395   \n",
       " 4     -0.246503 -0.538679  0.131311  0.832004  ...  0.266232  0.873553   \n",
       " ...         ...       ...       ...       ...  ...       ...       ...   \n",
       " 55870  0.425420  0.368931 -0.337017  0.751782  ...  0.911805  0.880740   \n",
       " 55871  0.747234  0.502675 -0.560923  0.607262  ...  0.889275  0.903055   \n",
       " 55872  0.786345  0.769699 -0.418527  0.597815  ...  0.843400  0.899782   \n",
       " 55873  0.693917  0.734702 -0.149538  0.623108  ...  0.790261  0.928971   \n",
       " 55874  0.344984  0.164792  0.509582  0.618142  ...  0.810770  0.910152   \n",
       " \n",
       "              14        15        16        17        18        19        20  \\\n",
       " 0      0.452813 -0.375800 -0.197114 -0.677816 -0.395864 -0.315340 -0.010655   \n",
       " 1     -0.074147 -0.087164 -0.607093 -0.368695 -0.741116 -0.188775  0.150085   \n",
       " 2     -0.344867  0.662313 -0.718643  0.119225 -0.628298  0.390711  0.147500   \n",
       " 3     -0.330687  0.891210 -0.826001 -0.203952 -0.360892  0.522659  0.245915   \n",
       " 4     -0.172410  0.523424 -0.810981 -0.056530 -0.066425  0.146766  0.451478   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 55870  0.579875  0.543719  0.172596  0.669962 -0.239215  0.755595  0.742628   \n",
       " 55871  0.407239  0.093362  0.494885  0.287612 -0.457826  0.804776  0.921419   \n",
       " 55872 -0.145309  0.314542  0.367583  0.133061  0.208245  0.839307  0.908114   \n",
       " 55873 -0.094710  0.413759  0.690577  0.118558  0.487566  0.847068  0.760944   \n",
       " 55874  0.435101  0.516283  0.710131  0.265259  0.566952  0.775728  0.308790   \n",
       " \n",
       "              21  \n",
       " 0      0.522583  \n",
       " 1      0.186614  \n",
       " 2     -0.037273  \n",
       " 3     -0.234264  \n",
       " 4     -0.077627  \n",
       " ...         ...  \n",
       " 55870 -0.399587  \n",
       " 55871 -0.640513  \n",
       " 55872 -0.326440  \n",
       " 55873  0.468611  \n",
       " 55874  0.830576  \n",
       " \n",
       " [55875 rows x 22 columns],\n",
       "           Unnamed: 0         2         3         4         5         6  \\\n",
       " 0       CELG & PXD_0  0.679183  0.199338  0.310183  0.364170  0.438221   \n",
       " 1      CELG & PXD_20  0.352477  0.622226  0.615217 -0.240156  0.782224   \n",
       " 2      CELG & PXD_40 -0.488062  0.574526  0.539969 -0.448536  0.788591   \n",
       " 3      CELG & PXD_60 -0.561882  0.604127  0.722692 -0.113043  0.675429   \n",
       " 4      CELG & PXD_80 -0.314456  0.439548  0.674778  0.283974 -0.246503   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 55870     FOX & MA_0  0.071451  0.595682  0.844499  0.395403  0.425420   \n",
       " 55871    FOX & MA_20  0.008614  0.771566  0.850320  0.710853  0.747234   \n",
       " 55872    FOX & MA_40  0.243556  0.921268  0.632534  0.888777  0.786345   \n",
       " 55873    FOX & MA_60  0.563173  0.951715  0.386957  0.900770  0.693917   \n",
       " 55874    FOX & MA_80  0.684904  0.943243  0.413954  0.825214  0.344984   \n",
       " \n",
       "               7         8         9        10  ...        13        14  \\\n",
       " 0     -0.794414 -0.515353  0.241255  0.635788  ...  0.494260  0.452813   \n",
       " 1     -0.790989  0.313710  0.517477  0.603807  ...  0.687713 -0.074147   \n",
       " 2     -0.423448  0.407719  0.686462  0.832706  ...  0.845183 -0.344867   \n",
       " 3     -0.338822 -0.117613  0.831165  0.854545  ...  0.906395 -0.330687   \n",
       " 4     -0.538679  0.131311  0.832004  0.823378  ...  0.873553 -0.172410   \n",
       " ...         ...       ...       ...       ...  ...       ...       ...   \n",
       " 55870  0.368931 -0.337017  0.751782  0.528945  ...  0.880740  0.579875   \n",
       " 55871  0.502675 -0.560923  0.607262  0.187975  ...  0.903055  0.407239   \n",
       " 55872  0.769699 -0.418527  0.597815  0.273112  ...  0.899782 -0.145309   \n",
       " 55873  0.734702 -0.149538  0.623108  0.173150  ...  0.928971 -0.094710   \n",
       " 55874  0.164792  0.509582  0.618142  0.141614  ...  0.910152  0.435101   \n",
       " \n",
       "              15        16        17        18        19        20        21  \\\n",
       " 0     -0.375800 -0.197114 -0.677816 -0.395864 -0.315340 -0.010655  0.522583   \n",
       " 1     -0.087164 -0.607093 -0.368695 -0.741116 -0.188775  0.150085  0.186614   \n",
       " 2      0.662313 -0.718643  0.119225 -0.628298  0.390711  0.147500 -0.037273   \n",
       " 3      0.891210 -0.826001 -0.203952 -0.360892  0.522659  0.245915 -0.234264   \n",
       " 4      0.523424 -0.810981 -0.056530 -0.066425  0.146766  0.451478 -0.077627   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 55870  0.543719  0.172596  0.669962 -0.239215  0.755595  0.742628 -0.399587   \n",
       " 55871  0.093362  0.494885  0.287612 -0.457826  0.804776  0.921419 -0.640513   \n",
       " 55872  0.314542  0.367583  0.133061  0.208245  0.839307  0.908114 -0.326440   \n",
       " 55873  0.413759  0.690577  0.118558  0.487566  0.847068  0.760944  0.468611   \n",
       " 55874  0.516283  0.710131  0.265259  0.566952  0.775728  0.308790  0.830576   \n",
       " \n",
       "              22  \n",
       " 0     -0.035216  \n",
       " 1      0.298936  \n",
       " 2      0.104392  \n",
       " 3     -0.019786  \n",
       " 4      0.252466  \n",
       " ...         ...  \n",
       " 55870  0.800925  \n",
       " 55871  0.758608  \n",
       " 55872  0.823716  \n",
       " 55873  0.179644  \n",
       " 55874 -0.768193  \n",
       " \n",
       " [55875 rows x 22 columns],\n",
       "           Unnamed: 0         3         4         5         6         7  \\\n",
       " 0       CELG & PXD_0  0.199338  0.310183  0.364170  0.438221 -0.794414   \n",
       " 1      CELG & PXD_20  0.622226  0.615217 -0.240156  0.782224 -0.790989   \n",
       " 2      CELG & PXD_40  0.574526  0.539969 -0.448536  0.788591 -0.423448   \n",
       " 3      CELG & PXD_60  0.604127  0.722692 -0.113043  0.675429 -0.338822   \n",
       " 4      CELG & PXD_80  0.439548  0.674778  0.283974 -0.246503 -0.538679   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 55870     FOX & MA_0  0.595682  0.844499  0.395403  0.425420  0.368931   \n",
       " 55871    FOX & MA_20  0.771566  0.850320  0.710853  0.747234  0.502675   \n",
       " 55872    FOX & MA_40  0.921268  0.632534  0.888777  0.786345  0.769699   \n",
       " 55873    FOX & MA_60  0.951715  0.386957  0.900770  0.693917  0.734702   \n",
       " 55874    FOX & MA_80  0.943243  0.413954  0.825214  0.344984  0.164792   \n",
       " \n",
       "               8         9        10        11  ...        14        15  \\\n",
       " 0     -0.515353  0.241255  0.635788  0.903754  ...  0.452813 -0.375800   \n",
       " 1      0.313710  0.517477  0.603807  0.922857  ... -0.074147 -0.087164   \n",
       " 2      0.407719  0.686462  0.832706  0.861398  ... -0.344867  0.662313   \n",
       " 3     -0.117613  0.831165  0.854545  0.605477  ... -0.330687  0.891210   \n",
       " 4      0.131311  0.832004  0.823378  0.783975  ... -0.172410  0.523424   \n",
       " ...         ...       ...       ...       ...  ...       ...       ...   \n",
       " 55870 -0.337017  0.751782  0.528945  0.767827  ...  0.579875  0.543719   \n",
       " 55871 -0.560923  0.607262  0.187975  0.726629  ...  0.407239  0.093362   \n",
       " 55872 -0.418527  0.597815  0.273112  0.785604  ... -0.145309  0.314542   \n",
       " 55873 -0.149538  0.623108  0.173150  0.854680  ... -0.094710  0.413759   \n",
       " 55874  0.509582  0.618142  0.141614  0.879099  ...  0.435101  0.516283   \n",
       " \n",
       "              16        17        18        19        20        21        22  \\\n",
       " 0     -0.197114 -0.677816 -0.395864 -0.315340 -0.010655  0.522583 -0.035216   \n",
       " 1     -0.607093 -0.368695 -0.741116 -0.188775  0.150085  0.186614  0.298936   \n",
       " 2     -0.718643  0.119225 -0.628298  0.390711  0.147500 -0.037273  0.104392   \n",
       " 3     -0.826001 -0.203952 -0.360892  0.522659  0.245915 -0.234264 -0.019786   \n",
       " 4     -0.810981 -0.056530 -0.066425  0.146766  0.451478 -0.077627  0.252466   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 55870  0.172596  0.669962 -0.239215  0.755595  0.742628 -0.399587  0.800925   \n",
       " 55871  0.494885  0.287612 -0.457826  0.804776  0.921419 -0.640513  0.758608   \n",
       " 55872  0.367583  0.133061  0.208245  0.839307  0.908114 -0.326440  0.823716   \n",
       " 55873  0.690577  0.118558  0.487566  0.847068  0.760944  0.468611  0.179644   \n",
       " 55874  0.710131  0.265259  0.566952  0.775728  0.308790  0.830576 -0.768193   \n",
       " \n",
       "              23  \n",
       " 0     -0.275846  \n",
       " 1     -0.548077  \n",
       " 2     -0.619524  \n",
       " 3     -0.568927  \n",
       " 4     -0.082630  \n",
       " ...         ...  \n",
       " 55870 -0.836800  \n",
       " 55871 -0.690420  \n",
       " 55872 -0.531648  \n",
       " 55873 -0.484676  \n",
       " 55874 -0.728613  \n",
       " \n",
       " [55875 rows x 22 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pycodestyle:2:80: E501 line too long (82 > 79 characters)\n",
      "INFO:pycodestyle:10:73: E225 missing whitespace around operator\n",
      "INFO:pycodestyle:10:80: E501 line too long (95 > 79 characters)\n",
      "INFO:pycodestyle:18:80: E501 line too long (91 > 79 characters)\n",
      "INFO:pycodestyle:25:80: E501 line too long (80 > 79 characters)\n",
      "INFO:pycodestyle:40:80: E501 line too long (85 > 79 characters)\n",
      "INFO:pycodestyle:41:80: E501 line too long (110 > 79 characters)\n",
      "INFO:pycodestyle:43:42: E221 multiple spaces before operator\n",
      "INFO:pycodestyle:43:80: E501 line too long (170 > 79 characters)\n",
      "INFO:pycodestyle:44:72: E251 unexpected spaces around keyword / parameter equals\n",
      "INFO:pycodestyle:44:74: E251 unexpected spaces around keyword / parameter equals\n",
      "INFO:pycodestyle:44:80: E501 line too long (93 > 79 characters)\n",
      "INFO:pycodestyle:47:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "def gen_data_corr(items: list, corr_ind: list) -> \"pd.DataFrame\":\n",
    "    tmp_corr = dataset_df[items[0]].rolling(window=100).corr(dataset_df[items[1]])\n",
    "    tmp_corr = tmp_corr.iloc[corr_ind].values\n",
    "    data_df = pd.DataFrame(tmp_corr.reshape(-1, 24), dtype=\"float32\")\n",
    "    ind = [f\"{items[0]} & {items[1]}_{i}\" for i in range(0, 100, 20)]\n",
    "    data_df.index = ind\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def gen_train_data(items: list, corr_ind: list, save_file: bool = False)-> \"four pd.DataFrame\":\n",
    "    train_df = pd.DataFrame(dtype=\"float32\")\n",
    "    dev_df = pd.DataFrame(dtype=\"float32\")\n",
    "    test1_df = pd.DataFrame(dtype=\"float32\")\n",
    "    test2_df = pd.DataFrame(dtype=\"float32\")\n",
    "\n",
    "    for pair in tqdm(combinations(items, 2)):\n",
    "        data_df = gen_data_corr([pair[0], pair[1]], corr_ind=corr_ind)\n",
    "        data_split = {'train': [0, 21], 'dev': [1, 22], 'test1': [2, 23], 'test2': [3, 24]}\n",
    "        train_df = pd.concat([train_df, data_df.iloc[:, 0:21]])\n",
    "        dev_df = pd.concat([dev_df, data_df.iloc[:, 1:22]])\n",
    "        test1_df = pd.concat([test1_df, data_df.iloc[:, 2:23]])\n",
    "        test2_df = pd.concat([test2_df, data_df.iloc[:, 3:24]])\n",
    "\n",
    "    if save_file:\n",
    "        before_arima_data_path = dataset_path/f\"{output_file_name}_before_arima\"\n",
    "        before_arima_data_path.mkdir(parents=True, exist_ok=True)\n",
    "        train_df.to_csv(before_arima_data_path/f\"{output_file_name}_train.csv\")\n",
    "        dev_df.to_csv(before_arima_data_path/f\"{output_file_name}_dev.csv\")\n",
    "        test1_df.to_csv(before_arima_data_path/f\"{output_file_name}_test1.csv\")\n",
    "        test2_df.to_csv(before_arima_data_path/f\"{output_file_name}_test2.csv\")\n",
    "\n",
    "    return train_df, dev_df, test1_df, test2_df\n",
    "\n",
    "\n",
    "before_arima_data_path = dataset_path/f\"{output_file_name}_before_arima\"\n",
    "train_df = before_arima_data_path/f\"{output_file_name}_train.csv\"\n",
    "dev_df = before_arima_data_path/f\"{output_file_name}_dev.csv\"\n",
    "test1_df = before_arima_data_path/f\"{output_file_name}_test1.csv\"\n",
    "test2_df = before_arima_data_path/f\"{output_file_name}_test2.csv\"\n",
    "if train_df.exists() and dev_df.exists() and test1_df.exists() and test2_df.exists():\n",
    "    corr_datasets = (pd.read_csv(train_df), pd.read_csv(dev_df), pd.read_csv(test1_df), pd.read_csv(test2_df))\n",
    "else:\n",
    "    corr_ind = list(range(99, 2400, 100))  + list(range(99+20, 2500, 100)) + list(range(99+40, 2500, 100)) + list(range(99+60, 2500, 100)) + list(range(99+80, 2500, 100))\n",
    "    corr_datasets = gen_train_data(items_implement, corr_ind, save_file = save_raw_corr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7976949-33c7-45c0-b6e9-c8cace53672a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ee34a-a8f6-4609-9e69-cfa66bc19100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def arima_model(dataset: \"pd.DataFrame\", save_file_period: str = \"\") -> (\"pd.DataFrame\", \"pd.DataFrame\", \"pd.DataFrame\"):\n",
    "    model_110 = ARIMA(order=(1, 1, 0), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_011 = ARIMA(order=(0, 1, 1), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_111 = ARIMA(order=(1, 1, 1), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_211 = ARIMA(order=(2, 1, 1), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_210 = ARIMA(order=(2, 1, 0), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    #model_330 = ARIMA(order=(3, 3, 0), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "\n",
    "    #model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210, \"model_330\": model_330}\n",
    "    model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210}\n",
    "    tested_models = []\n",
    "    arima_model = None\n",
    "    find_arima_model = False\n",
    "    arima_output_list = []\n",
    "    arima_resid_list = []\n",
    "    arima_model_info_list = []\n",
    "    for corr_pair, corr_series in tqdm(dataset.iterrows()):\n",
    "        while not find_arima_model:\n",
    "            try:\n",
    "                for model_key in model_dict:\n",
    "                    if model_key not in tested_models:\n",
    "                        test_model = model_dict[model_key].fit(corr_series[:-1]) # only use first 20 corrletaion coefficient to fit ARIMA model\n",
    "                        if arima_model is None:\n",
    "                            arima_model = test_model\n",
    "                            arima_model_name = model_key\n",
    "                        elif arima_model.aic() <= test_model.aic():\n",
    "                            pass\n",
    "                        else:\n",
    "                            arima_model = test_model\n",
    "                            arima_model_name = model_key\n",
    "                    tested_models.append(model_key)\n",
    "            except Exception:\n",
    "                if len(model_dict)-1 != 0:\n",
    "                    del model_dict[model_key]\n",
    "                else:\n",
    "                    err_logger.error(f\"fatal error, {corr_pair} doesn't have appropriate arima model\\n\", exc_info=True)\n",
    "                    break\n",
    "            else:\n",
    "                #model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210, \"model_330\": model_330}\n",
    "                model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210}\n",
    "                tested_models.clear()\n",
    "                find_arima_model = True\n",
    "        try:\n",
    "            arima_pred = list(arima_model.predict(n_periods=1))\n",
    "        except Exception:\n",
    "            err_logger.error(f\"{corr_pair} in {save_file_period} be predicted by {arima_model_name}(its aic:{arima_model.aic()}) getting error:\\n\", exc_info=True)\n",
    "            dataset = dataset.drop(index=corr_pair)\n",
    "        else:\n",
    "            arima_pred_in_sample = list(arima_model.predict_in_sample())\n",
    "            arima_pred_in_sample = [np.mean(arima_pred_in_sample[1:])] + arima_pred_in_sample[1:]\n",
    "            arima_output = arima_pred_in_sample + arima_pred\n",
    "            arima_output = np.clip(np.array(arima_output), -1, 1)\n",
    "            arima_output_list.append(arima_output)\n",
    "\n",
    "            arima_resid = pd.Series(np.array(corr_series) - arima_output)\n",
    "            arima_resid_list.append(np.array(arima_resid))\n",
    "            arima_infos = [corr_pair, arima_model_name]\n",
    "            for attr in [\"aic\", \"pvalues\", \"params\", \"arparams\", \"aroots\", \"maparams\", \"maroots\"]:\n",
    "                try:\n",
    "                    val = getattr(arima_model, attr)()\n",
    "                except AttributeError:\n",
    "                    arima_infos.append(None)\n",
    "                else:\n",
    "                    arima_infos.append(val)\n",
    "            else:\n",
    "                arima_model_info_list.append(arima_infos)\n",
    "        finally:\n",
    "            find_arima_model = False\n",
    "\n",
    "\n",
    "    arima_model_info_df = pd.DataFrame(arima_model_info_list, dtype=\"float32\", columns=[\"items\", \"model_name\", \"aic\", \"pvalues\", \"params\", \"arparams\", \"aroots\", \"maparams\", \"maroots\"]).set_index(\"items\")\n",
    "    arima_output_df = pd.DataFrame(arima_output_list, dtype=\"float32\", index=dataset.index)\n",
    "    arima_resid_df = pd.DataFrame(arima_resid_list, dtype=\"float32\", index=dataset.index)\n",
    "\n",
    "    if save_file_period:\n",
    "        after_arima_data_path = dataset_path/f\"{output_file_name}_after_arima\"\n",
    "        after_arima_data_path.mkdir(parents=True, exist_ok=True)\n",
    "        arima_model_info_df.to_csv(after_arima_data_path/f'{output_file_name}_arima_model_info_{save_file_period}.csv')\n",
    "        arima_output_df.to_csv(after_arima_data_path/f'{output_file_name}_arima_output_{save_file_period}.csv')\n",
    "        arima_resid_df.to_csv(after_arima_data_path/f'{output_file_name}_arima_resid_{save_file_period}.csv')\n",
    "\n",
    "    return arima_output_df, arima_resid_df, arima_model_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a253c7-552c-4c6c-9072-8a6cc83297c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pycodestyle:2:80: E501 line too long (92 > 79 characters)\n",
      "INFO:pycodestyle:3:80: E501 line too long (84 > 79 characters)\n",
      "INFO:pycodestyle:4:80: E501 line too long (82 > 79 characters)\n",
      "INFO:pycodestyle:5:80: E501 line too long (89 > 79 characters)\n",
      "INFO:pycodestyle:8:80: E501 line too long (93 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "after_arima_data_path = dataset_path/f\"{output_file_name}_after_arima\"\n",
    "arima_model_info_df = after_arima_data_path/f'{output_file_name}_arima_model_info_test2.csv'\n",
    "arima_output_df = after_arima_data_path/f'{output_file_name}_arima_output_test2.csv'\n",
    "arima_resid_df = after_arima_data_path/f'{output_file_name}_arima_resid_test2.csv'\n",
    "if arima_model_info_df.exists() and arima_output_df.exists() and arima_resid_df.exists():\n",
    "    pass\n",
    "else:\n",
    "    for (file_name, dataset) in tqdm(zip(['train', 'dev', 'test1', 'test2'], corr_datasets)):\n",
    "        if save_train_info_arima_resid_data:\n",
    "            arima_model(dataset, save_file_period=file_name)\n",
    "        else:\n",
    "            arima_model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb455ad-4103-403d-a65f-ba8a13038295",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed36f1c-62c7-4874-a3a4-1aaf35bcdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset.from_tensor_slices(dict(pd.read_csv(f'./dataset/after_arima/arima_resid_train.csv')))\n",
    "after_arima_data_path = dataset_path/f\"{output_file_name}_after_arima\"\n",
    "lstm_train_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_train.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_train_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_train.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_dev_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_dev.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_dev_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_dev.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_test1_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test1.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_test1_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test1.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_test2_X = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test2.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_test2_Y = pd.read_csv(after_arima_data_path/f'{output_file_name}_arima_resid_test2.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "\n",
    "lstm_train_X = lstm_train_X.values.reshape(-1, 20, 1)\n",
    "lstm_train_Y = lstm_train_Y.values.reshape(-1, 1)\n",
    "lstm_dev_X = lstm_dev_X.values.reshape(-1, 20, 1)\n",
    "lstm_dev_Y = lstm_dev_Y.values.reshape(-1, 1)\n",
    "lstm_test1_X = lstm_test1_X.values.reshape(-1, 20, 1)\n",
    "lstm_test1_Y = lstm_test1_Y.values.reshape(-1, 1)\n",
    "lstm_test2_X = lstm_test2_X.values.reshape(-1, 20, 1)\n",
    "lstm_test2_Y = lstm_test2_Y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df49f64-a93a-4104-b07d-dfbd0a688004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def double_tanh(x):\n",
    "    return (tf.math.tanh(x) *2)\n",
    "\n",
    "\n",
    "def build_many_one_lstm():\n",
    "    inputs = Input(shape=(20, 1))\n",
    "    lstm_1 = LSTM(units=10, kernel_regularizer=l1_l2(0.2, 0.0), bias_regularizer=l1_l2(0.2, 0.0), activation=\"tanh\", dropout=0.1)(inputs)\n",
    "    outputs = Dense(units=1, activation=double_tanh)(lstm_1)\n",
    "    return keras.Model(inputs, outputs, name=\"many_one_lstm\")\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "lstm_model = build_many_one_lstm()\n",
    "lstm_model.summary()\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2b47f-ad31-431f-8ded-1e2acf98d7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = Path('./models/')\n",
    "log_dir = Path('./models/lstm_train_logs/')\n",
    "res_dir = Path('./results/')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "res_dir.mkdir(parents=True, exist_ok=True)\n",
    "res_csv_path = res_dir/f'{output_file_name}_LSTM_evaluation.csv'\n",
    "res_csv_path.touch(exist_ok=True)\n",
    "with open(res_csv_path, 'r+') as f:\n",
    "    if not f.read():\n",
    "        f.write(\"epoch,TRAIN_MSE,DEV_MSE,TEST1_MSE,TEST2_MSE,TRAIN_MAE,DEV_MAE,TEST1_MAE,TEST2_MAE\")\n",
    "\n",
    "res_df = pd.read_csv(res_csv_path)\n",
    "saved_model_list = [int(p.stem.split('_')[1]) for p in model_dir.glob('*.h5')]\n",
    "model_cbk = TensorBoard(log_dir=log_dir)\n",
    "epoch_start = max(saved_model_list) if saved_model_list else 1\n",
    "max_epoch = 300\n",
    "batch_size = 64\n",
    "\n",
    "for epoch_num in tqdm(range(epoch_start, max_epoch)):\n",
    "    if epoch_num > 1:\n",
    "        lstm_model = load_model(model_dir/f\"{output_file_name}_epoch_{epoch_num - 1}.h5\", custom_objects={'double_tanh':double_tanh})\n",
    "\n",
    "    save_model = ModelCheckpoint(model_dir/f\"{output_file_name}_epoch_{epoch_num}.h5\",\n",
    "                                                 monitor='loss', verbose=1, mode='min', save_best_only=False)\n",
    "    lstm_model.fit(lstm_train_X, lstm_train_Y, epochs=1, batch_size=batch_size, shuffle=True, callbacks=[model_cbk, save_model])\n",
    "\n",
    "    # test the model\n",
    "    score_train = lstm_model.evaluate(lstm_train_X, lstm_train_Y)\n",
    "    score_dev = lstm_model.evaluate(lstm_dev_X, lstm_dev_Y)\n",
    "    score_test1 = lstm_model.evaluate(lstm_test1_X, lstm_test1_Y)\n",
    "    score_test2 = lstm_model.evaluate(lstm_test2_X, lstm_test2_Y)\n",
    "    res_each_epoch_df = pd.DataFrame(np.array([epoch_num, score_train[0], score_dev[0], \n",
    "                                               score_test1[0], score_test2[0], \n",
    "                                               score_train[1], score_dev[1], \n",
    "                                               score_test1[1], score_test2[1]]).reshape(-1, 9),\n",
    "                                    columns=[\"epoch\", \"TRAIN_MSE\", \"DEV_MSE\", \"TEST1_MSE\", \n",
    "                                             \"TEST2_MSE\", \"TRAIN_MAE\", \"DEV_MAE\",\n",
    "                                             \"TEST1_MAE\",\"TEST2_MAE\"])\n",
    "    res_df = pd.concat([res_df, res_each_epoch_df])\n",
    "\n",
    "res_df.to_csv(res_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bb3d3-1516-4da3-ab8e-f27bd25b0945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
