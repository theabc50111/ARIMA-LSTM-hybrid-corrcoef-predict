{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28ce7c7-6cde-4c96-9c04-526e1394cb60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.15 s (started: 2022-12-05 17:43:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "from pprint import pformat\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import silhouette_score, make_scorer\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import fbeta_score\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"/tf/correlation-coef-predict/ywt_library\")\n",
    "import data_generation\n",
    "from data_generation import data_gen_cfg\n",
    "from stl_decompn import stl_decompn\n",
    "from corr_property import calc_corr_ser_property\n",
    "\n",
    "\n",
    "with open('../config/data_config.yaml') as f:\n",
    "    data = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "matplotlib_logger = logging.getLogger(\"matplotlib\")\n",
    "matplotlib_logger.setLevel(logging.ERROR)\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# logger_list = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "# print(logger_list)\n",
    "\n",
    "# %load_ext pycodestyle_magic\n",
    "# %pycodestyle_on --ignore E501\n",
    "logging.debug(pformat(data_cfg, indent=1, width=100, compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651a732-13ea-40cc-b683-99fcec1ee8c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ac923-2662-45b3-aab2-46cd99bef517",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data implement & output setting & testset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8fbe48-0772-489a-acbc-c2c786050f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 625 Âµs (started: 2022-12-05 17:43:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "res_dir = Path('./results/')\n",
    "res_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# setting of output files\n",
    "save_corr_data = True\n",
    "save_arima_resid_data = False\n",
    "# data implement setting\n",
    "data_implement = \"SP500_20082017\"  # ['BITCOIN_NVDA', 'PAPER_EVA_1', 'PAPER_EVA_2', 'PAPER_EVA_3',\n",
    "                                                          # 'PAPER_EVA_4', 'PAPER_EVA_5', 'SP500_19972007', 'SP500_20082017',\n",
    "                                                          # 'SP500_20082017_CONSUMER_DISCRETIONARY', 'TEST_CASE', TETUAN_POWER', 'TW50_20082018']\n",
    "# etl set setting\n",
    "etl_items_setting = \"-etl_all\"  # -etl_train|-etl_all\n",
    "# data split period setting, only suit for only settings of Korean paper\n",
    "data_split_setting = \"-data_sp_test2\"\n",
    "# Decide how to calculate corr_ser\n",
    "corr_ser_clac_method = \"corr_ser_calc_regular\" # corr_ser_calc_regular|corr_ser_calc_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcf3224-3a83-4793-a105-c480f5bb151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:===== len(train_set): 150, len(all_set): 446, len(test_set): 296 =====\n",
      "INFO:root:===== len(etl set): 446 =====\n",
      "INFO:root:===== file_name basis:sp500_20082017-etl_all, fig_title basis:SP500_20082017-etl_all-data_sp_test2 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 103 ms (started: 2022-12-05 17:43:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(data_cfg[\"DATASETS\"][data_implement]['FILE_PATH'])\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns)  # all data\n",
    "train_set = data_cfg[\"DATASETS\"][data_implement]['TRAIN_SET']\n",
    "test_set = data_cfg['DATASETS'][data_implement]['TEST_SET'] if data_cfg['DATASETS'][data_implement].get('TEST_SET') else [p for p in all_set if p not in train_set]  # all data - train data\n",
    "logging.info(f\"===== len(train_set): {len(train_set)}, len(all_set): {len(all_set)}, len(test_set): {len(test_set)} =====\")\n",
    "\n",
    "# test items implement settings\n",
    "items_implement = train_set if etl_items_setting == \"-etl_train\" else all_set\n",
    "logging.info(f\"===== len(etl set): {len(items_implement)} =====\")\n",
    "\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + etl_items_setting\n",
    "fig_title = data_implement + etl_items_setting + data_split_setting\n",
    "logging.info(f\"===== file_name basis:{output_file_name}, fig_title basis:{fig_title} =====\")\n",
    "# display(dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d7485-bf75-440f-9232-c10ceab8f40d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load or Create Correlation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfc41c1-4bfe-4db2-876a-980159ad8f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2009-08-03</th>\n",
       "      <th>2009-12-23</th>\n",
       "      <th>2010-05-19</th>\n",
       "      <th>2010-10-11</th>\n",
       "      <th>2011-03-04</th>\n",
       "      <th>2011-07-27</th>\n",
       "      <th>2011-12-16</th>\n",
       "      <th>2012-05-11</th>\n",
       "      <th>2012-10-03</th>\n",
       "      <th>2013-03-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2013-12-13</th>\n",
       "      <th>2014-05-09</th>\n",
       "      <th>2014-10-01</th>\n",
       "      <th>2015-02-25</th>\n",
       "      <th>2015-07-20</th>\n",
       "      <th>2015-12-09</th>\n",
       "      <th>2016-05-04</th>\n",
       "      <th>2016-09-26</th>\n",
       "      <th>2017-02-17</th>\n",
       "      <th>2017-07-12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>items</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EXR &amp; RCL_0</th>\n",
       "      <td>0.734117</td>\n",
       "      <td>0.905061</td>\n",
       "      <td>0.785018</td>\n",
       "      <td>0.721939</td>\n",
       "      <td>0.671190</td>\n",
       "      <td>-0.351678</td>\n",
       "      <td>0.613028</td>\n",
       "      <td>0.247936</td>\n",
       "      <td>0.728215</td>\n",
       "      <td>0.796137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049241</td>\n",
       "      <td>0.817157</td>\n",
       "      <td>0.070484</td>\n",
       "      <td>0.722049</td>\n",
       "      <td>0.211542</td>\n",
       "      <td>0.620790</td>\n",
       "      <td>0.378626</td>\n",
       "      <td>0.467885</td>\n",
       "      <td>-0.063265</td>\n",
       "      <td>-0.147673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; CLX_0</th>\n",
       "      <td>0.773642</td>\n",
       "      <td>0.737735</td>\n",
       "      <td>0.801525</td>\n",
       "      <td>0.884755</td>\n",
       "      <td>0.367367</td>\n",
       "      <td>0.522993</td>\n",
       "      <td>-0.162647</td>\n",
       "      <td>0.725597</td>\n",
       "      <td>0.693520</td>\n",
       "      <td>0.751288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243108</td>\n",
       "      <td>-0.253300</td>\n",
       "      <td>0.023788</td>\n",
       "      <td>0.943677</td>\n",
       "      <td>0.293699</td>\n",
       "      <td>0.929081</td>\n",
       "      <td>0.193722</td>\n",
       "      <td>0.560946</td>\n",
       "      <td>0.546624</td>\n",
       "      <td>0.283479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; NSC_0</th>\n",
       "      <td>0.840588</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.861761</td>\n",
       "      <td>0.841920</td>\n",
       "      <td>0.660949</td>\n",
       "      <td>0.853405</td>\n",
       "      <td>0.843548</td>\n",
       "      <td>-0.381795</td>\n",
       "      <td>0.592307</td>\n",
       "      <td>0.631024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108781</td>\n",
       "      <td>0.727363</td>\n",
       "      <td>0.201595</td>\n",
       "      <td>-0.203210</td>\n",
       "      <td>-0.535949</td>\n",
       "      <td>0.599261</td>\n",
       "      <td>0.294131</td>\n",
       "      <td>-0.606118</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.136238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; CXO_0</th>\n",
       "      <td>0.668084</td>\n",
       "      <td>0.829077</td>\n",
       "      <td>0.863273</td>\n",
       "      <td>0.836825</td>\n",
       "      <td>0.874292</td>\n",
       "      <td>-0.304559</td>\n",
       "      <td>0.938664</td>\n",
       "      <td>-0.040469</td>\n",
       "      <td>0.563963</td>\n",
       "      <td>0.332670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716390</td>\n",
       "      <td>0.897075</td>\n",
       "      <td>0.393437</td>\n",
       "      <td>0.077130</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.375815</td>\n",
       "      <td>0.262811</td>\n",
       "      <td>-0.741779</td>\n",
       "      <td>-0.015711</td>\n",
       "      <td>-0.168771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; AKAM_0</th>\n",
       "      <td>0.199625</td>\n",
       "      <td>0.802655</td>\n",
       "      <td>0.972332</td>\n",
       "      <td>0.663723</td>\n",
       "      <td>-0.533803</td>\n",
       "      <td>-0.429652</td>\n",
       "      <td>0.847281</td>\n",
       "      <td>0.399358</td>\n",
       "      <td>0.897392</td>\n",
       "      <td>0.291804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653256</td>\n",
       "      <td>0.630602</td>\n",
       "      <td>0.498340</td>\n",
       "      <td>0.448854</td>\n",
       "      <td>0.470507</td>\n",
       "      <td>-0.716135</td>\n",
       "      <td>0.186378</td>\n",
       "      <td>0.347881</td>\n",
       "      <td>-0.376157</td>\n",
       "      <td>0.043027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              2009-08-03  2009-12-23  2010-05-19  2010-10-11  2011-03-04  \\\n",
       "items                                                                      \n",
       "EXR & RCL_0     0.734117    0.905061    0.785018    0.721939    0.671190   \n",
       "EXR & CLX_0     0.773642    0.737735    0.801525    0.884755    0.367367   \n",
       "EXR & NSC_0     0.840588    0.722513    0.861761    0.841920    0.660949   \n",
       "EXR & CXO_0     0.668084    0.829077    0.863273    0.836825    0.874292   \n",
       "EXR & AKAM_0    0.199625    0.802655    0.972332    0.663723   -0.533803   \n",
       "\n",
       "              2011-07-27  2011-12-16  2012-05-11  2012-10-03  2013-03-01  ...  \\\n",
       "items                                                                     ...   \n",
       "EXR & RCL_0    -0.351678    0.613028    0.247936    0.728215    0.796137  ...   \n",
       "EXR & CLX_0     0.522993   -0.162647    0.725597    0.693520    0.751288  ...   \n",
       "EXR & NSC_0     0.853405    0.843548   -0.381795    0.592307    0.631024  ...   \n",
       "EXR & CXO_0    -0.304559    0.938664   -0.040469    0.563963    0.332670  ...   \n",
       "EXR & AKAM_0   -0.429652    0.847281    0.399358    0.897392    0.291804  ...   \n",
       "\n",
       "              2013-12-13  2014-05-09  2014-10-01  2015-02-25  2015-07-20  \\\n",
       "items                                                                      \n",
       "EXR & RCL_0    -0.049241    0.817157    0.070484    0.722049    0.211542   \n",
       "EXR & CLX_0    -0.243108   -0.253300    0.023788    0.943677    0.293699   \n",
       "EXR & NSC_0     0.108781    0.727363    0.201595   -0.203210   -0.535949   \n",
       "EXR & CXO_0     0.716390    0.897075    0.393437    0.077130    0.002771   \n",
       "EXR & AKAM_0    0.653256    0.630602    0.498340    0.448854    0.470507   \n",
       "\n",
       "              2015-12-09  2016-05-04  2016-09-26  2017-02-17  2017-07-12  \n",
       "items                                                                     \n",
       "EXR & RCL_0     0.620790    0.378626    0.467885   -0.063265   -0.147673  \n",
       "EXR & CLX_0     0.929081    0.193722    0.560946    0.546624    0.283479  \n",
       "EXR & NSC_0     0.599261    0.294131   -0.606118   -0.000291    0.136238  \n",
       "EXR & CXO_0     0.375815    0.262811   -0.741779   -0.015711   -0.168771  \n",
       "EXR & AKAM_0   -0.716135    0.186378    0.347881   -0.376157    0.043027  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 624 ms (started: 2022-12-05 17:43:16 +00:00)\n"
     ]
    }
   ],
   "source": [
    "corr_data_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}-corr_data\"\n",
    "corr_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "data_length = int(len(dataset_df)/data_gen_cfg[\"CORR_WINDOW\"])*data_gen_cfg[\"CORR_WINDOW\"]\n",
    "corr_ser_len_max = int((data_length-data_gen_cfg[\"CORR_WINDOW\"])/data_gen_cfg[\"CORR_STRIDE\"])\n",
    "max_data_div_start_add = 0  # In the Korea paper, each pair has 5 corr_series(due to diversifing train data).\n",
    "                            # BUT we only need to take one, so take 0 as arg.\n",
    "corr_ind = []\n",
    "\n",
    "# DEFAULT SETTING: data_gen_cfg[\"DATA_DIV_STRIDE\"] == 20, data_gen_cfg[\"CORR_WINDOW\"]==100, data_gen_cfg[\"CORR_STRIDE\"]==100\n",
    "data_end_init = corr_ser_len_max * data_gen_cfg[\"CORR_STRIDE\"]\n",
    "for i in range(0, max_data_div_start_add+1, data_gen_cfg[\"DATA_DIV_STRIDE\"]):\n",
    "    corr_ind.extend(list(range(data_gen_cfg[\"CORR_WINDOW\"]-1+i, data_end_init+bool(i)*data_gen_cfg[\"CORR_STRIDE\"], data_gen_cfg[\"CORR_STRIDE\"])))  # only suit for settings of paper\n",
    "\n",
    "train_df_path = corr_data_dir/f\"{output_file_name}-corr_train.csv\"\n",
    "dev_df_path = corr_data_dir/f\"{output_file_name}-corr_dev.csv\"\n",
    "test1_df_path = corr_data_dir/f\"{output_file_name}-corr_test1.csv\"\n",
    "test2_df_path = corr_data_dir/f\"{output_file_name}-corr_test2.csv\"\n",
    "all_corr_df_paths = dict(zip([\"train_df\", \"dev_df\", \"test1_df\", \"test2_df\"],\n",
    "                             [train_df_path, dev_df_path, test1_df_path, test2_df_path]))\n",
    "if all([df_path.exists() for df_path in all_corr_df_paths.values()]):\n",
    "    corr_datasets = [pd.read_csv(df_path, index_col=[\"items\"]) for df_path in all_corr_df_paths.values()]\n",
    "else:\n",
    "    corr_datasets = data_generation.gen_train_data(items_implement, raw_data_df=dataset_df, corr_ser_len_max=corr_ser_len_max, corr_df_paths=all_corr_df_paths, corr_ind=corr_ind, max_data_div_start_add=max_data_div_start_add, save_file=save_corr_data)\n",
    "\n",
    "if data_split_setting == \"-data_sp_test2\":\n",
    "    corr_dataset = corr_datasets[3]\n",
    "    display(corr_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48c13c-7752-4105-bd68-205b0763cbaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate properties of Corrlelation series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8aca586-6ce7-4ff8-bc64-fc1b07d996f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Min of corr_ser_mean:-0.2366300617142857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr_stl_period</th>\n",
       "      <th>corr_stl_resid</th>\n",
       "      <th>corr_stl_trend_std</th>\n",
       "      <th>corr_stl_trend_coef</th>\n",
       "      <th>corr_ser_mean</th>\n",
       "      <th>corr_ser_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>items</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EXR &amp; RCL_0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.933266</td>\n",
       "      <td>0.061371</td>\n",
       "      <td>-0.013425</td>\n",
       "      <td>0.457621</td>\n",
       "      <td>0.375633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; CLX_0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.640171</td>\n",
       "      <td>0.090185</td>\n",
       "      <td>-0.017592</td>\n",
       "      <td>0.457273</td>\n",
       "      <td>0.382823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; NSC_0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.234424</td>\n",
       "      <td>0.186347</td>\n",
       "      <td>-0.055383</td>\n",
       "      <td>0.366751</td>\n",
       "      <td>0.481276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; CXO_0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.707243</td>\n",
       "      <td>0.109238</td>\n",
       "      <td>-0.032370</td>\n",
       "      <td>0.318106</td>\n",
       "      <td>0.517407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXR &amp; AKAM_0</th>\n",
       "      <td>10</td>\n",
       "      <td>2.130711</td>\n",
       "      <td>0.081423</td>\n",
       "      <td>-0.013917</td>\n",
       "      <td>0.339993</td>\n",
       "      <td>0.494846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              corr_stl_period  corr_stl_resid  corr_stl_trend_std  \\\n",
       "items                                                               \n",
       "EXR & RCL_0                10        0.933266            0.061371   \n",
       "EXR & CLX_0                10        0.640171            0.090185   \n",
       "EXR & NSC_0                10        1.234424            0.186347   \n",
       "EXR & CXO_0                10        0.707243            0.109238   \n",
       "EXR & AKAM_0               10        2.130711            0.081423   \n",
       "\n",
       "              corr_stl_trend_coef  corr_ser_mean  corr_ser_std  \n",
       "items                                                           \n",
       "EXR & RCL_0             -0.013425       0.457621      0.375633  \n",
       "EXR & CLX_0             -0.017592       0.457273      0.382823  \n",
       "EXR & NSC_0             -0.055383       0.366751      0.481276  \n",
       "EXR & CXO_0             -0.032370       0.318106      0.517407  \n",
       "EXR & AKAM_0            -0.013917       0.339993      0.494846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 72.8 ms (started: 2022-12-05 17:43:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# stl_decompn(corr_datasets[0].iloc[0,::], overview=True)\n",
    "if corr_ser_clac_method == \"corr_ser_calc_regular\":\n",
    "    corr_property_df_path = res_dir/f\"{output_file_name}{data_split_setting}-corr_series_property.csv\"\n",
    "    corr_property_df = calc_corr_ser_property(corr_dataset=corr_dataset, corr_property_df_path=corr_property_df_path)\n",
    "elif corr_ser_clac_method == \"corr_ser_calc_abs\":\n",
    "    # calculate corr_property_df with abs(corr_dataset)\n",
    "    corr_property_df_path = res_dir/f\"{output_file_name}{data_split_setting}-corr_series_abs_property.csv\"\n",
    "    corr_property_df = calc_corr_ser_property(corr_dataset=corr_dataset.abs(), corr_property_df_path=corr_property_df_path)\n",
    "\n",
    "logging.info(f\"Min of corr_ser_mean:{corr_property_df.loc[::,'corr_ser_mean'].min()}\")\n",
    "display(corr_property_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b7022-6869-4990-bf4d-49bd97b239db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cf997-4986-4a35-b75c-f01fb2f659d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## calculate dissimilarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3226fa6a-9702-46f7-a425-a88d79342b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Min of distance_mat:items\n",
      "A       0.003982\n",
      "AAL    -0.188621\n",
      "AAP    -0.102435\n",
      "AAPL    0.012430\n",
      "ABC    -0.057590\n",
      "          ...   \n",
      "XRAY   -0.072159\n",
      "XRX    -0.009821\n",
      "YUM    -0.044450\n",
      "ZBH    -0.017642\n",
      "ZION   -0.166037\n",
      "Length: 446, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>items</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>...</th>\n",
       "      <th>XEC</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>items</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300171</td>\n",
       "      <td>0.179568</td>\n",
       "      <td>0.436743</td>\n",
       "      <td>0.577418</td>\n",
       "      <td>0.303949</td>\n",
       "      <td>0.475528</td>\n",
       "      <td>0.535575</td>\n",
       "      <td>0.476134</td>\n",
       "      <td>0.251038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354400</td>\n",
       "      <td>0.256961</td>\n",
       "      <td>0.469498</td>\n",
       "      <td>0.476738</td>\n",
       "      <td>0.311286</td>\n",
       "      <td>0.562695</td>\n",
       "      <td>0.380345</td>\n",
       "      <td>0.375182</td>\n",
       "      <td>0.579993</td>\n",
       "      <td>0.416577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>0.300171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225579</td>\n",
       "      <td>0.114826</td>\n",
       "      <td>0.206002</td>\n",
       "      <td>0.144048</td>\n",
       "      <td>0.118043</td>\n",
       "      <td>0.244483</td>\n",
       "      <td>0.307133</td>\n",
       "      <td>0.019801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162172</td>\n",
       "      <td>0.254855</td>\n",
       "      <td>0.318696</td>\n",
       "      <td>0.346005</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.139709</td>\n",
       "      <td>0.182037</td>\n",
       "      <td>0.168956</td>\n",
       "      <td>0.316168</td>\n",
       "      <td>0.217373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.179568</td>\n",
       "      <td>0.225579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229584</td>\n",
       "      <td>0.111223</td>\n",
       "      <td>0.196831</td>\n",
       "      <td>0.260031</td>\n",
       "      <td>0.303690</td>\n",
       "      <td>0.439518</td>\n",
       "      <td>0.367005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284346</td>\n",
       "      <td>0.271700</td>\n",
       "      <td>0.288445</td>\n",
       "      <td>0.181168</td>\n",
       "      <td>0.126932</td>\n",
       "      <td>0.217595</td>\n",
       "      <td>0.256557</td>\n",
       "      <td>0.370499</td>\n",
       "      <td>0.098102</td>\n",
       "      <td>0.196226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.436743</td>\n",
       "      <td>0.114826</td>\n",
       "      <td>0.229584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428568</td>\n",
       "      <td>0.375260</td>\n",
       "      <td>0.399825</td>\n",
       "      <td>0.426043</td>\n",
       "      <td>0.403874</td>\n",
       "      <td>0.237163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370374</td>\n",
       "      <td>0.278069</td>\n",
       "      <td>0.506003</td>\n",
       "      <td>0.287878</td>\n",
       "      <td>0.313295</td>\n",
       "      <td>0.339121</td>\n",
       "      <td>0.207699</td>\n",
       "      <td>0.450198</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.239409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABC</th>\n",
       "      <td>0.577418</td>\n",
       "      <td>0.206002</td>\n",
       "      <td>0.111223</td>\n",
       "      <td>0.428568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.337482</td>\n",
       "      <td>0.399384</td>\n",
       "      <td>0.381007</td>\n",
       "      <td>0.150348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243465</td>\n",
       "      <td>0.234941</td>\n",
       "      <td>0.478613</td>\n",
       "      <td>0.306360</td>\n",
       "      <td>0.120575</td>\n",
       "      <td>0.333874</td>\n",
       "      <td>0.294883</td>\n",
       "      <td>0.243171</td>\n",
       "      <td>0.498930</td>\n",
       "      <td>0.342968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 446 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "items         A       AAL       AAP      AAPL       ABC       ABT       ACN  \\\n",
       "items                                                                         \n",
       "A      1.000000  0.300171  0.179568  0.436743  0.577418  0.303949  0.475528   \n",
       "AAL    0.300171  1.000000  0.225579  0.114826  0.206002  0.144048  0.118043   \n",
       "AAP    0.179568  0.225579  1.000000  0.229584  0.111223  0.196831  0.260031   \n",
       "AAPL   0.436743  0.114826  0.229584  1.000000  0.428568  0.375260  0.399825   \n",
       "ABC    0.577418  0.206002  0.111223  0.428568  1.000000  0.408493  0.337482   \n",
       "\n",
       "items      ADBE       ADI       ADM  ...       XEC       XEL        XL  \\\n",
       "items                                ...                                 \n",
       "A      0.535575  0.476134  0.251038  ...  0.354400  0.256961  0.469498   \n",
       "AAL    0.244483  0.307133  0.019801  ...  0.162172  0.254855  0.318696   \n",
       "AAP    0.303690  0.439518  0.367005  ...  0.284346  0.271700  0.288445   \n",
       "AAPL   0.426043  0.403874  0.237163  ...  0.370374  0.278069  0.506003   \n",
       "ABC    0.399384  0.381007  0.150348  ...  0.243465  0.234941  0.478613   \n",
       "\n",
       "items      XLNX       XOM      XRAY       XRX       YUM       ZBH      ZION  \n",
       "items                                                                        \n",
       "A      0.476738  0.311286  0.562695  0.380345  0.375182  0.579993  0.416577  \n",
       "AAL    0.346005  0.016293  0.139709  0.182037  0.168956  0.316168  0.217373  \n",
       "AAP    0.181168  0.126932  0.217595  0.256557  0.370499  0.098102  0.196226  \n",
       "AAPL   0.287878  0.313295  0.339121  0.207699  0.450198  0.397351  0.239409  \n",
       "ABC    0.306360  0.120575  0.333874  0.294883  0.243171  0.498930  0.342968  \n",
       "\n",
       "[5 rows x 446 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 238 ms (started: 2022-12-05 17:43:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def process_index(items):\n",
    "    item_1 = items[0].strip(\" \")\n",
    "    item_2 = items[1].strip(\" \")\n",
    "    item_2 = item_2[:-2]\n",
    "\n",
    "    return (item_1, item_2)\n",
    "\n",
    "\n",
    "def gen_dist_mat(data_ser: \"multi-ind pd.Series\", raw_df: \"pd.DataFrame\", input_similiarity: bool = True):\n",
    "    data_ser = data_ser.copy()\n",
    "    tmp_df = data_ser.unstack()\n",
    "    unstack_missing_items = [item for item in raw_df.columns if item not in tmp_df.columns or item not in tmp_df.index]   # åªé .unstack()ä¾è½æææ¼æå©çµitemï¼.unstack()å¾çdf ä¸å·æéå©çµitemçèªå·±å°èªå·±çrowï½col\n",
    "    for item in unstack_missing_items:\n",
    "        data_ser.loc[item, item] = 0\n",
    "\n",
    "    non_symmetry_mat = data_ser.unstack(fill_value=0)\n",
    "    dissimilarity_mat = non_symmetry_mat.T + non_symmetry_mat\n",
    "    non_symmetry_mat_sum_double = round(non_symmetry_mat.sum().sum() * 2, 10)\n",
    "    dissimilarity_mat_sum = round(dissimilarity_mat.sum().sum(), 10)\n",
    "    assert non_symmetry_mat_sum_double == dissimilarity_mat_sum, \"Error happens during the computation of dissimilarity matrix.\"\n",
    "    assert not dissimilarity_mat.isnull().any().any(), \"Dissimilarity matrix contains missing values.\"\n",
    "    np.fill_diagonal(dissimilarity_mat.values, 1)  # check by: tmp_df = gen_data_corr([\"A\", \"A\"], dataset_df, corr_ser_len_max=corr_ser_len_max, corr_ind=corr_ind, max_data_div_start_add=max_data_div_start_add); tmp_df.iloc[::, 3:].mean(axis=1)\n",
    "    if input_similiarity:\n",
    "        dissimilarity_mat = 1 - dissimilarity_mat.abs()  # This might get wrong by using abs(), because that would mix up corr = -1 & corr = 1\n",
    "\n",
    "    return dissimilarity_mat\n",
    "\n",
    "\n",
    "corr_mean = corr_property_df.loc[::,\"corr_ser_mean\"]\n",
    "corr_mean.index = corr_mean.index.str.split('&').map(process_index)\n",
    "distance_mat = gen_dist_mat(corr_mean, dataset_df,  input_similiarity=False)\n",
    "# test\n",
    "# test_stock_tickers = [\"ED\", \"BAC\", \"XEL\", \"MA\"]\n",
    "# test_distance_mat = distance_mat.loc[test_stock_tickers, test_stock_tickers]\n",
    "# display(test_distance_mat)  # comlpete: (ED, BAC), (XEL), (MA) -> (ED, BAC), (XEL, MA)  -> (ED, BAC, XEL, MA)\n",
    "#                             # single: (ED, BAC), (XEL), (MA) -> (ED, BAC, XEL), (MA)  -> (ED, BAC, XEL, MA)\n",
    "logging.info(f\"Min of distance_mat:{distance_mat.min()}\")\n",
    "display(distance_mat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61189a-728e-44d1-8ecb-8e42b0ca92fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## calculate cluster label for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a073dbd-cae4-4c0e-b6ab-b39c05329fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrchy_cluste.n_clusters_: 2\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1]), array([288, 158]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 3\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2]), array([158, 193,  95]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 4\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2, 3]), array([193, 133,  95,  25]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 5\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2, 3, 4]), array([103,  90,  95,  25, 133]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 6\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2, 3, 4, 5]), array([ 95,  90,  59,  25, 133,  44]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 7\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2, 3, 4, 5, 6]), array([ 90, 133,  59,  25,  77,  44,  18]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 8\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2, 3, 4, 5, 6, 7]), array([133,  77,  59,  43,  47,  44,  18,  25]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 9\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([77, 47, 59, 36, 97, 44, 18, 25, 43]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 10\n",
      "hrchy_cluste.labels and whose number of instances: (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([47, 97, 59, 36, 37, 44, 18, 25, 43, 40]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 11\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), array([97, 37, 59, 36, 38, 44, 18, 25, 43, 40,  9]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 12\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([59, 37, 44, 36, 38, 31, 18, 25, 43, 40,  9, 66]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 13\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), array([44, 37, 31, 36, 38, 66, 18, 25, 43, 40,  9, 36, 23]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 14\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13]), array([37, 36, 31, 43, 38, 66, 18, 25, 41, 40,  9, 36, 23,  3]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 15\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), array([36, 43, 31, 41, 38, 66, 18, 25, 26, 40,  9, 36, 23,  3, 11]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 16\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]), array([43, 38, 31, 41, 40, 66, 18, 25, 26, 20,  9, 36, 23,  3, 11, 16]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 17\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]), array([38, 40, 31, 41, 24, 66, 18, 25, 26, 20,  9, 36, 23,  3, 11, 16, 19]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 18\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17]), array([31, 40, 66, 41, 24, 36, 18, 25, 26, 20,  9, 30, 23,  3, 11, 16, 19,\n",
      "        8]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 19\n",
      "hrchy_cluste.labels and whose number of instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18]), array([66, 40, 18, 41, 24, 36, 30, 25, 26, 20,  9, 30, 23,  3, 11, 16, 19,\n",
      "        8,  1]))\n",
      "--------------------------------------------------\n",
      "hrchy_cluste.n_clusters_: 11\n",
      "hrchy_cluste.labels and whose instances: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), array([97, 37, 59, 36, 38, 44, 18, 25, 43, 40,  9]))\n",
      "hrchy_cluster.n_leaves_: 446\n",
      "hrchy_cluster.n_features_in_: 446\n",
      "--------------------------------------------------\n",
      "time: 98.5 ms (started: 2022-12-05 17:43:39 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def calc_silhouette_label_freq_std(estimator: \"sklearn.cluster.<cluster_model>\", X: \"pd.DataFrame\", silhouette_score_ratio: int = 0.1, silhouette_metric: str = \"precomputed\") -> float:\n",
    "    estimator.fit(X)\n",
    "    cluster_labels = estimator.labels_\n",
    "    num_labels = len(set(cluster_labels))\n",
    "    num_samples = len(X.index)\n",
    "    labels_symbol, label_freq = np.unique(cluster_labels, return_counts=True)\n",
    "    if num_labels == 1 or num_labels == num_samples:\n",
    "        return -1\n",
    "    else:\n",
    "        return silhouette_score_ratio * silhouette_score(X, cluster_labels, metric=silhouette_metric) + (1 - silhouette_score_ratio) * (1 / np.array(label_freq).std())\n",
    "\n",
    "\n",
    "def hrchy_clustering_distance_threshold_rs(X: \"pd.DataFrame\", data_mat_mode: str = \"precomputed\", verbose: int = 0):\n",
    "\n",
    "    param_dict = {\"n_clusters\": [None], \"affinity\": [data_mat_mode],\n",
    "                  \"linkage\": [\"single\", \"complete\", \"average\"],\n",
    "                  \"distance_threshold\": uniform(loc=0.55, scale=0.6)}\n",
    "    cv = [(slice(None), slice(None))]\n",
    "    hrchy_clustering_rs = RandomizedSearchCV(estimator=AgglomerativeClustering(), param_distributions=param_dict,\n",
    "                                             n_iter=100000, scoring=calc_silhouette_label_freq_std, cv=cv, n_jobs=-1)\n",
    "    hrchy_clustering_rs.fit(X)\n",
    "\n",
    "    if verbose==1:\n",
    "        print(f\"hrchy_clustering_rs.best_estimator_: {hrchy_clustering_rs.best_estimator_}\")\n",
    "        print(f\"hrchy_clustering_rs.best_params_: {hrchy_clustering_rs.best_params_}\")\n",
    "        print(f\"hrchy_clustering_rs.best_score_: {hrchy_clustering_rs.best_score_}\")\n",
    "        print(f\"hrchy_clustering_rs.best_estimator_.n_leaves_: {hrchy_clustering_rs.best_estimator_.n_leaves_}\")\n",
    "        print(f\"hrchy_clustering_rs.best_estimator_.n_clusters_: {hrchy_clustering_rs.best_estimator_.n_clusters_}\")\n",
    "        print(f\"np.unique(hrchy_clustering_rs.best_estimator_.labels_): {np.unique(hrchy_clustering_rs.best_estimator_.labels_, return_counts=True)}\")\n",
    "        print(f\"hrchy_clustering_rs.best_estimator_.labels_: {hrchy_clustering_rs.best_estimator_.labels_}\")\n",
    "        print(f\"hrchy_clustering_rs.n_features_in_: {hrchy_clustering_rs.n_features_in_}\")\n",
    "        print(f\"hrchy_clustering_rs.feature_names_in_: {hrchy_clustering_rs.feature_names_in_}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "    return hrchy_clustering_rs.best_estimator_\n",
    "\n",
    "\n",
    "def hrchy_clustering_n_cluster_gs(X: \"pd.DataFrame\", data_mat_mode: str = \"precomputed\", verbose: int = 0):\n",
    "\n",
    "    param_dict = {\"n_clusters\": range(2, 20), \"affinity\": [data_mat_mode],\n",
    "                  \"linkage\": [\"single\", \"complete\", \"average\"]}\n",
    "    cv = [(slice(None), slice(None))]\n",
    "    hrchy_clustering_gs = GridSearchCV(estimator=AgglomerativeClustering(), param_grid=param_dict,\n",
    "                                       scoring=calc_silhouette_label_freq_std, cv=cv, n_jobs=-1)\n",
    "    hrchy_clustering_gs.fit(X)\n",
    "\n",
    "    if verbose==1:\n",
    "        print(f\"hrchy_clustering_gs.best_estimator_: {hrchy_clustering_gs.best_estimator_}\")\n",
    "        print(f\"hrchy_clustering_gs.best_params_: {hrchy_clustering_gs.best_params_}\")\n",
    "        print(f\"hrchy_clustering_gs.best_score_: {hrchy_clustering_gs.best_score_}\")\n",
    "        print(f\"hrchy_clustering_gs.best_estimator_.n_leaves_: {hrchy_clustering_gs.best_estimator_.n_leaves_}\")\n",
    "        print(f\"hrchy_clustering_gs.best_estimator_.n_clusters_: {hrchy_clustering_gs.best_estimator_.n_clusters_}\")\n",
    "        print(f\"np.unique(hrchy_clustering_gs.best_estimator_.labels_): {np.unique(hrchy_clustering_gs.best_estimator_.labels_, return_counts=True)}\")\n",
    "        print(f\"hrchy_clustering_gs.best_estimator_.labels_: {hrchy_clustering_gs.best_estimator_.labels_}\")\n",
    "        print(f\"hrchy_clustering_gs.n_features_in_: {hrchy_clustering_gs.n_features_in_}\")\n",
    "        print(f\"hrchy_clustering_gs.feature_names_in_: {hrchy_clustering_gs.feature_names_in_}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "    return hrchy_clustering_gs.best_estimator_\n",
    "\n",
    "\n",
    "def obs_hrchy_cluster_instances(X: \"pd.DataFrame\", data_mat_mode: str = \"precomputed\", verbose: int = 1):\n",
    "\n",
    "    for n in range(2, 20):\n",
    "        hrchy_cluster = AgglomerativeClustering(n_clusters=n, linkage=\"complete\", affinity=data_mat_mode, compute_distances=True)\n",
    "        hrchy_cluster.fit(X)\n",
    "\n",
    "        if verbose==1:\n",
    "            print(f\"hrchy_cluste.n_clusters_: {hrchy_cluster.n_clusters_}\")\n",
    "            print(f\"hrchy_cluste.labels and whose number of instances: {np.unique(hrchy_cluster.labels_, return_counts=True)}\")\n",
    "            # print(f\"(ticker, cluster label): {list(zip(X.index, hrchy_cluster.labels_))}\")\n",
    "            # print(f\"The estimated number of connected components:{hrchy_cluster.n_connected_components_}\")\n",
    "            # print(f\"hrchy_cluster.n_leaves_: {hrchy_cluster.n_leaves_}\")\n",
    "            # print(f\"hrchy_cluster.n_features_in_: {hrchy_cluster.n_features_in_}\")\n",
    "            print(\"-\"*50)\n",
    "\n",
    "\n",
    "def hrchy_cluster_fixed_n_cluster(X: \"pd.DataFrame\", n: int, data_mat_mode: str = \"precomputed\", verbose: int = 1):\n",
    "\n",
    "    hrchy_cluster = AgglomerativeClustering(n_clusters=n, linkage=\"complete\", affinity=data_mat_mode)\n",
    "    hrchy_cluster.fit(X)\n",
    "\n",
    "    if verbose==1:\n",
    "        print(f\"hrchy_cluste.n_clusters_: {hrchy_cluster.n_clusters_}\")\n",
    "        print(f\"hrchy_cluste.labels and whose instances: {np.unique(hrchy_cluster.labels_, return_counts=True)}\")\n",
    "        print(f\"hrchy_cluster.n_leaves_: {hrchy_cluster.n_leaves_}\")\n",
    "        print(f\"hrchy_cluster.n_features_in_: {hrchy_cluster.n_features_in_}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "    return hrchy_cluster\n",
    "\n",
    "\n",
    "obs_hrchy_cluster_instances(distance_mat)\n",
    "fixed_n_cluster = 11  # Determin by observe result of obs_hrchy_cluster_instances()\n",
    "fixed_n_cluster_hrchy_cluster = hrchy_cluster_fixed_n_cluster(distance_mat, n=fixed_n_cluster)\n",
    "# distance_threshold_hrchy_cluster = hrchy_clustering_distance_threshold_rs(dissimilarity_mat, verbose=0)\n",
    "# n_cluster_hrchy_cluster = hrchy_clustering_n_cluster_gs(dissimilarity_mat, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63eab05-a4d7-416d-817d-118f83e0f32f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## plot cluster label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fbbb8-a060-4c7e-957d-ff8671151ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_labels_distribution(trained_cluster: \"sklearn.cluster.<cluster_model>\", cluster_name: str):\n",
    "    x_major_locator = MultipleLocator(1)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(x_major_locator)\n",
    "    plt.bar(np.unique(trained_cluster.labels_, return_counts=True)[0], np.unique(trained_cluster.labels_, return_counts=True)[1])\n",
    "    plt.grid()\n",
    "    plt.ylabel(\"instances in cluster\")\n",
    "    plt.xlabel(\"cluster label\")\n",
    "    plt.title(f\"{cluster_name}\\n {fig_title}\")\n",
    "    plt.show()  # findout elbow point\n",
    "    plt.close()\n",
    "    logging.info(f\"cluster of each point distribution: {np.unique(trained_cluster.labels_, return_counts=True)}\")\n",
    "\n",
    "plot_cluster_labels_distribution(fixed_n_cluster_hrchy_cluster, f\"Hirerarchy clustering with {fixed_n_cluster} n_clusters\")\n",
    "# plot_cluster_labels_distribution(n_cluster_hrchy_cluster, \"Hirerarchy clustering with n_clusters\")\n",
    "# plot_cluster_labels_distribution(distance_threshold_hrchy_cluster, \"Hirerarchy clustering with distance threshold\")\n",
    "# print(hrchy_cluster_labels_df.loc[hrchy_cluster_labels_df[\"hrchy_cluster_label\"]==4, \"items\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc31dae-4ad5-4974-be50-6e99cbfedd09",
   "metadata": {},
   "source": [
    "## output cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d684cf2-abc2-44dd-bc3f-6579a2a6bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_items_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}-cluster\"\n",
    "cluster_items_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if fixed_n_cluster:\n",
    "    output_cluster = fixed_n_cluster_hrchy_cluster  # the value of output_cluster depend on performance which shows in plot cluster label distribution\n",
    "    output_cluster_name = f\"corr_mat_hrchy_{fixed_n_cluster}_cluster\"\n",
    "\n",
    "hrchy_cluster_labels_df = pd.DataFrame(output_cluster.labels_, index=distance_mat.index, columns=[f\"{output_cluster_name}_label\"]).reset_index()\n",
    "hrchy_cluster_labels_df.to_csv(cluster_items_dir/f\"{output_file_name}-{corr_ser_clac_method}-{output_cluster_name}.csv\")\n",
    "logging.info(f\"{output_file_name}-{corr_ser_clac_method}-{output_cluster_name}.csv has been save to {cluster_items_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa1eaf-3921-4f56-9fe9-169e19c50f67",
   "metadata": {
    "tags": []
   },
   "source": [
    "# plot correlation coffecient distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8ab23-bd5c-4e24-92b5-a61c4fcea458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {'train_data--comb(150,2)': train_corr_series_concat, 'all_data--comb(445,2)': all_corr_series_concat, 'other_data--comb(295,2)': other_corr_series_concat}\n",
    "etl_types = [\"boxplot\", \"histogram\", \"qqplot\", \"Emprical Cumulative Density\"]\n",
    "fig, axes = plt.subplots(figsize=(20, 20),nrows=len(etl_types), ncols=len(datasets), sharex=False, sharey=False, dpi=100)\n",
    "\n",
    "for row, etl_type in enumerate(etl_types):\n",
    "    for col,dataset_key in enumerate(datasets):\n",
    "        # print(row, etl_type, col, dataset_key, datasets[dataset_key])\n",
    "        s = axes[row, col]\n",
    "        s.set_title(f\"{dataset_key}: \\n{etl_type}\", fontsize=24)\n",
    "        if etl_type==\"boxplot\":\n",
    "            s.boxplot(datasets[dataset_key], showmeans=True)\n",
    "        elif etl_type==\"histogram\":\n",
    "            s.hist(datasets[dataset_key], bins=[b/10 for b in range(-13,14)])\n",
    "        elif etl_type==\"qqplot\":\n",
    "            percents = [0.001, 0.2, 0.5, 0.8, 0.999]\n",
    "            #x,y = [norm.ppf(p) for p in percents], [np.quantile(train_corr_series_concat, p) for p in percents]\n",
    "            x,y = [norm.ppf(p) for p in percents], [np.quantile(datasets[dataset_key], p) for p in percents]\n",
    "            sm.qqplot(datasets[dataset_key], line='q', ax=s)\n",
    "            s.scatter(x,y, c='m', marker='x', s=300)\n",
    "        elif etl_type==\"Emprical Cumulative Density\":\n",
    "            pd.Series(datasets[dataset_key]).value_counts().sort_index().cumsum().plot(ax=s)\n",
    "\n",
    "# åé, é¿åå­åæ¨ç±¤äºç¸éç\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/dataset_exploration.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bdbb5-58e5-4529-bd8d-781395f18015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[dataset_key, datasets[dataset_key].std()] for dataset_key in datasets], \n",
    "                  columns=['Dataset', 'Standard deviation'])\n",
    "ax = sns.barplot(x='Dataset', y='Standard deviation', data=df)\n",
    "ax.set_title('std of correlation')\n",
    "ax.set(ylim=[0.47, 0.475])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xticks(rotation=60)\n",
    "plt.savefig(\"./results/dataset_exploration_2.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924fcc9-455d-42b1-b08f-ced180ce03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_corr_series_concat)\n",
    "# plt.hist(train_corr_series, bins=[b/10 for b in range(-13,14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e0835-ae6c-4cca-969b-e2e33f608f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr_series_df = gen_corr_series(None, \"train_dataset.csv\", from_file=True, concat_all=False)\n",
    "all_corr_series_df = gen_corr_series(None, \"445_dataset.csv\", from_file=True, concat_all=False)\n",
    "other_corr_series_df = gen_corr_series(None, \"295_dataset.csv\", from_file=True, concat_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5754944-5cd5-41f1-8c37-e607ba544e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {'train_data--comb(150,2)': train_corr_series_df, 'all_data--comb(445,2)': all_corr_series_df, 'other_data--comb(295,2)': other_corr_series_df}\n",
    "etl_types = [\"boxplot\", \"histogram\"]\n",
    "static_types = [\"mean\", \"std\"]\n",
    "fig, axes = plt.subplots(figsize=(30, 30),nrows=len(list(product(etl_types, static_types))), ncols=len(datasets), sharex=False, sharey=False, dpi=100)\n",
    "\n",
    "for row, (etl_type, static_type) in enumerate(product(etl_types, static_types)):\n",
    "    for col,dataset_key in enumerate(datasets):\n",
    "        s = axes[row, col]\n",
    "        s.set_title(f\"{dataset_key}: \\n{etl_type}_{static_type}\", fontsize=24)\n",
    "        if etl_type==\"boxplot\":\n",
    "            s.boxplot(datasets[dataset_key].iloc[:, ::5].describe().loc[static_type,:], showmeans=True)\n",
    "        elif etl_type==\"histogram\":\n",
    "            s.hist(datasets[dataset_key].iloc[:, ::5].describe().loc[static_type,:], bins=[b/10 for b in range(-13,14)])\n",
    "\n",
    "fig.suptitle(f\"Each correlation_series static property _20220718\", fontsize=24)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# åé, é¿åå­åæ¨ç±¤äºç¸éç\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"./results/dataset_exploration_3.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3beb76-3499-4905-96cc-4d208947a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_corr_series_df)\n",
    "display(train_corr_series_df.iloc[:,::5])\n",
    "display(train_corr_series_df.iloc[:,::5].describe())\n",
    "display(train_corr_series_df.iloc[:,::5].describe().loc['std',:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
