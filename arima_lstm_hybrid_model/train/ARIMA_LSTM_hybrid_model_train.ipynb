{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41660f84-97c9-4162-a708-f601b3b7a3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.77 s (started: 2022-12-04 12:35:19 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "from pprint import pformat\n",
    "import traceback\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pmdarima.arima import ARIMA, auto_arima\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"/tf/correlation-coef-predict/ywt_library\")\n",
    "import data_generation\n",
    "from data_generation import data_gen_cfg\n",
    "from ywt_arima import arima_model, arima_err_logger_init\n",
    "\n",
    "with open('../../config/data_config.yaml') as f:\n",
    "    data = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# %load_ext pycodestyle_magic\n",
    "# %pycodestyle_on --ignore E501\n",
    "logging.debug(pformat(data_cfg, indent=1, width=100, compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a012b1-6376-486e-b5dd-93c76929fc3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcae291-e762-4e5d-8740-05e845af7a34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data implement & output setting & trainset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167474f5-dd41-487c-a140-54d699e47621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 602 Âµs (started: 2022-12-04 12:35:21 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# setting of output files\n",
    "save_corr_data = True\n",
    "save_arima_resid_data = True\n",
    "# data implement setting\n",
    "data_implement = \"SP500_20082017\"  # watch options by operate: print(data_cfg[\"DATASETS\"].keys())\n",
    "# train set setting\n",
    "train_items_setting = \"-train_train\"  # -train_train|-train_all\n",
    "# data split  period setting, only suit for only settings of Korean paper\n",
    "data_split_settings = [\"-data_sp_train\", \"-data_sp_dev\", \"-data_sp_test1\", \"-data_sp_test2\", ]\n",
    "# lstm_hyper_params\n",
    "lstm_hyper_param = \"-kS_hyper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4fc57b1-5e84-49a3-8e15-bb6ae816af9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:===== len(train_set): 150, len(all_set): 446, len(test_set): 296 =====\n",
      "INFO:root:===== len(train set): 150 =====\n",
      "INFO:root:===== file_name basis:sp500_20082017-train_train =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms (started: 2022-12-04 12:35:21 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# data loading & implement setting\n",
    "dataset_df = pd.read_csv(data_cfg[\"DATASETS\"][data_implement]['FILE_PATH'])\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns)  # all data\n",
    "train_set = data_cfg[\"DATASETS\"][data_implement]['TRAIN_SET']\n",
    "test_set = data_cfg['DATASETS'][data_implement]['TEST_SET'] if data_cfg['DATASETS'][data_implement].get('TEST_SET') else [p for p in all_set if p not in train_set]  # all data - train data\n",
    "logging.info(f\"===== len(train_set): {len(train_set)}, len(all_set): {len(all_set)}, len(test_set): {len(test_set)} =====\")\n",
    "\n",
    "# train items implement settings\n",
    "items_implement = train_set if train_items_setting == \"-train_train\" else all_set\n",
    "logging.info(f\"===== len(train set): {len(items_implement)} =====\")\n",
    "\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + train_items_setting\n",
    "logging.info(f\"===== file_name basis:{output_file_name} =====\")\n",
    "# display(dataset_df)\n",
    "\n",
    "# output folder settings\n",
    "corr_data_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}-corr_data\"\n",
    "arima_result_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}-arima_res\"\n",
    "model_dir = Path('./save_models/')\n",
    "lstm_log_dir = Path('./save_models/lstm_train_logs/')\n",
    "res_dir = Path('./results/')\n",
    "corr_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "arima_result_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "lstm_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "res_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3cab1-9974-4aac-a85c-f418ab7395c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load or Create Correlation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8090b6a-e720-413f-9e59-1f512ff0dc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 355 ms (started: 2022-12-04 12:35:21 +00:00)\n"
     ]
    }
   ],
   "source": [
    "data_length = int(len(dataset_df)/data_gen_cfg[\"CORR_WINDOW\"])*data_gen_cfg[\"CORR_WINDOW\"]\n",
    "corr_ser_len_max = int((data_length-data_gen_cfg[\"CORR_WINDOW\"])/data_gen_cfg[\"CORR_STRIDE\"])\n",
    "\n",
    "train_df_path = corr_data_dir/f\"{output_file_name}-corr_train.csv\"\n",
    "dev_df_path = corr_data_dir/f\"{output_file_name}-corr_dev.csv\"\n",
    "test1_df_path = corr_data_dir/f\"{output_file_name}-corr_test1.csv\"\n",
    "test2_df_path = corr_data_dir/f\"{output_file_name}-corr_test2.csv\"\n",
    "all_corr_df_paths = dict(zip([\"train_df\", \"dev_df\", \"test1_df\", \"test2_df\"],\n",
    "                             [train_df_path, dev_df_path, test1_df_path, test2_df_path]))\n",
    "if all([df_path.exists() for df_path in all_corr_df_paths.values()]):\n",
    "    corr_datasets = [pd.read_csv(df_path).set_index(\"items\") for df_path in all_corr_df_paths.values()]\n",
    "else:\n",
    "    corr_datasets = data_generation.gen_train_data(items_implement, raw_data_df=dataset_df, corr_df_paths=all_corr_df_paths, corr_ser_len_max=corr_ser_len_max, save_file=save_corr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7976949-33c7-45c0-b6e9-c8cace53672a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aca1214-5327-4b3f-92b6-c9830bc5da50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.16 ms (started: 2022-12-04 12:35:22 +00:00)\n"
     ]
    }
   ],
   "source": [
    "arima_result_path_basis = arima_result_dir/f'{output_file_name}.csv'\n",
    "arima_result_paths = []\n",
    "arima_result_types = [\"-arima_model_info\", \"-arima_output\", \"-arima_resid\"]\n",
    "arima_err_logger_init(Path(os.path.abspath(''))/f\"save_models\")\n",
    "\n",
    "\n",
    "for data_sp_setting in data_split_settings:\n",
    "    for arima_result_type in arima_result_types:\n",
    "        arima_result_paths.append(arima_result_dir/f'{output_file_name}{arima_result_type}{data_sp_setting}.csv')\n",
    "\n",
    "if all([df_path.exists() for df_path in arima_result_paths]):\n",
    "    pass\n",
    "else:\n",
    "    for (data_sp_setting, dataset) in tqdm(zip(data_split_settings, corr_datasets)):\n",
    "        arima_model(dataset, arima_result_path_basis=arima_result_path_basis, data_split_setting=data_sp_setting, save_file=save_arima_resid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb455ad-4103-403d-a65f-ba8a13038295",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83a42a-7794-4cc4-9e1e-a924d716eec5",
   "metadata": {},
   "source": [
    "## settings of input data of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed36f1c-62c7-4874-a3a4-1aaf35bcdc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 758 ms (started: 2022-12-04 12:35:22 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Dataset.from_tensor_slices(dict(pd.read_csv(f'./dataset/after_arima/arima_resid_train.csv')))\n",
    "lstm_train_X = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_train.csv', index_col=\"items\").iloc[::, :-1]\n",
    "lstm_train_Y = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_train.csv', index_col=\"items\").iloc[::, -1]\n",
    "lstm_dev_X = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_dev.csv', index_col=\"items\").iloc[::, :-1]\n",
    "lstm_dev_Y = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_dev.csv', index_col=\"items\").iloc[::, -1]\n",
    "lstm_test1_X = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_test1.csv', index_col=\"items\").iloc[::, :-1]\n",
    "lstm_test1_Y = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_test1.csv', index_col=\"items\").iloc[::, -1]\n",
    "lstm_test2_X = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_test2.csv', index_col=\"items\").iloc[::, :-1]\n",
    "lstm_test2_Y = pd.read_csv(arima_result_dir/f'{output_file_name}-arima_resid-data_sp_test2.csv', index_col=\"items\").iloc[::, -1]\n",
    "\n",
    "lstm_X_len = lstm_train_X.shape[1]\n",
    "lstm_Y_len = lstm_train_Y.shape[1] if len(lstm_train_Y.shape)>1 else 1\n",
    "lstm_train_X = lstm_train_X.values.reshape(-1, lstm_X_len, 1)\n",
    "lstm_train_Y = lstm_train_Y.values.reshape(-1, lstm_Y_len)\n",
    "lstm_dev_X = lstm_dev_X.values.reshape(-1, lstm_X_len, 1)\n",
    "lstm_dev_Y = lstm_dev_Y.values.reshape(-1, lstm_Y_len)\n",
    "lstm_test1_X = lstm_test1_X.values.reshape(-1,  lstm_X_len, 1)\n",
    "lstm_test1_Y = lstm_test1_Y.values.reshape(-1, lstm_Y_len)\n",
    "lstm_test2_X = lstm_test2_X.values.reshape(-1,  lstm_X_len, 1)\n",
    "lstm_test2_Y = lstm_test2_Y.values.reshape(-1, lstm_Y_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089da49-7fd9-4257-ac0e-c77418ec067a",
   "metadata": {},
   "source": [
    "## settings of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f34446a-65bc-4b4d-9de4-186d285dcd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 966 ms (started: 2022-12-04 12:35:23 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 12:35:23.712173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:23.718096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:23.718389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:23.719132: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 12:35:23.720351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:23.720519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:23.720667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:24.029868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:24.030064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:24.030224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 12:35:24.030359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model_log = TensorBoard(log_dir=lstm_log_dir)\n",
    "max_epoch = 300\n",
    "batch_size = 64\n",
    "lstm_metrics = ['mse', 'mae']\n",
    "\n",
    "if lstm_hyper_param == \"-kS_hyper\":\n",
    "    lstm_layer = LSTM(units=10, kernel_regularizer=l1_l2(0.2, 0.0), bias_regularizer=l1_l2(0.2, 0.0), activation=\"tanh\", dropout=0.1, name=f\"lstm{lstm_hyper_param}\")  # LSTM hyper params from ãSomething Old, Something New â A Hybrid Approach with ARIMA and LSTM to Increase Portfolio Stabilityã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df49f64-a93a-4104-b07d-dfbd0a688004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm1_fc1-kS_hyper\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " lstm-kS_hyper (LSTM)        (None, 10)                480       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 282 ms (started: 2022-12-04 12:35:24 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def double_tanh(x):\n",
    "    return (tf.math.tanh(x) *2)\n",
    "\n",
    "\n",
    "def build_many_one_lstm():\n",
    "    inputs = Input(shape=(20, 1))\n",
    "    lstm_1 = lstm_layer(inputs)\n",
    "    outputs = Dense(units=1, activation=double_tanh)(lstm_1)\n",
    "    return keras.Model(inputs, outputs, name=f\"lstm1_fc1{lstm_hyper_param}\")\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "lstm_model = build_many_one_lstm()\n",
    "lstm_model.summary()\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer=opt, metrics=lstm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2b47f-ad31-431f-8ded-1e2acf98d7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/299 [00:00<?, ?it/s]2022-12-04 12:35:25.720017: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-12-04 12:35:26.172066: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch1.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 3.0501 - mse: 0.2743 - mae: 0.4217\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 3.1034 - mse: 0.3276 - mae: 0.4628\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 3.1106 - mse: 0.3347 - mae: 0.4675\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 3.1370 - mse: 0.3611 - mae: 0.4845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 1/299 [00:17<1:27:20, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch2.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 2.3835 - mse: 0.2730 - mae: 0.4184\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 2.4488 - mse: 0.3383 - mae: 0.4682\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 2.4534 - mse: 0.3429 - mae: 0.4708\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 2.4817 - mse: 0.3711 - mae: 0.4894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 2/299 [00:33<1:22:43, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch3.h5\n",
      "1746/1746 [==============================] - 3s 1ms/step - loss: 1.9009 - mse: 0.2742 - mae: 0.4191\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.9689 - mse: 0.3421 - mae: 0.4704\n",
      "1746/1746 [==============================] - 4s 2ms/step - loss: 1.9728 - mse: 0.3460 - mae: 0.4725\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 1.9997 - mse: 0.3729 - mae: 0.4903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 3/299 [00:49<1:20:51, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch4.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.5936 - mse: 0.2767 - mae: 0.4207\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.6654 - mse: 0.3484 - mae: 0.4740\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.6678 - mse: 0.3508 - mae: 0.4754\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 1.6933 - mse: 0.3764 - mae: 0.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 4/299 [01:05<1:19:50, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch5.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.4042 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.4776 - mse: 0.3511 - mae: 0.4755\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.4794 - mse: 0.3529 - mae: 0.4766\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 1.5047 - mse: 0.3782 - mae: 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 5/299 [01:21<1:19:35, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch6.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.2296 - mse: 0.2777 - mae: 0.4212\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.3040 - mse: 0.3521 - mae: 0.4760\n",
      "1746/1746 [==============================] - 4s 2ms/step - loss: 1.3056 - mse: 0.3537 - mae: 0.4769\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 1.3312 - mse: 0.3793 - mae: 0.4938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 6/299 [01:38<1:19:28, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch7.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.0549 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.1284 - mse: 0.3511 - mae: 0.4755\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 1.1302 - mse: 0.3529 - mae: 0.4766\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 1.1554 - mse: 0.3782 - mae: 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 7/299 [01:54<1:19:10, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch8.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.8803 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.9540 - mse: 0.3514 - mae: 0.4757\n",
      "1746/1746 [==============================] - 4s 2ms/step - loss: 0.9558 - mse: 0.3532 - mae: 0.4767\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.9811 - mse: 0.3785 - mae: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 8/299 [02:10<1:19:01, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch9.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.7057 - mse: 0.2777 - mae: 0.4212\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.7798 - mse: 0.3518 - mae: 0.4759\n",
      "1746/1746 [==============================] - 4s 2ms/step - loss: 0.7815 - mse: 0.3535 - mae: 0.4768\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.8070 - mse: 0.3790 - mae: 0.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 9/299 [02:27<1:18:52, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch10.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.5311 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.6046 - mse: 0.3512 - mae: 0.4756\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.6064 - mse: 0.3530 - mae: 0.4766\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.6317 - mse: 0.3783 - mae: 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 10/299 [02:43<1:18:20, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch11.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3565 - mse: 0.2777 - mae: 0.4214\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.4298 - mse: 0.3509 - mae: 0.4754\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.4316 - mse: 0.3528 - mae: 0.4765\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.4568 - mse: 0.3779 - mae: 0.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 11/299 [02:59<1:17:53, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch12.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4212\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3522 - mse: 0.3520 - mae: 0.4760\n",
      "1746/1746 [==============================] - 4s 2ms/step - loss: 0.3538 - mse: 0.3536 - mae: 0.4768\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3794 - mse: 0.3792 - mae: 0.4937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 12/299 [03:15<1:17:37, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch13.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3514 - mse: 0.3512 - mae: 0.4756\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3532 - mse: 0.3530 - mae: 0.4766\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3785 - mse: 0.3783 - mae: 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 13/299 [03:32<1:17:38, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch14.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3516 - mse: 0.3514 - mae: 0.4757\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3534 - mse: 0.3532 - mae: 0.4767\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3787 - mse: 0.3785 - mae: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% 14/299 [03:48<1:17:02, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch15.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3515 - mse: 0.3513 - mae: 0.4756\n",
      "1746/1746 [==============================] - 4s 2ms/step - loss: 0.3533 - mse: 0.3531 - mae: 0.4766\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3786 - mse: 0.3784 - mae: 0.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% 15/299 [04:04<1:16:54, 16.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch16.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4214\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3511 - mse: 0.3509 - mae: 0.4754\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3529 - mse: 0.3527 - mae: 0.4765\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3781 - mse: 0.3779 - mae: 0.4930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% 16/299 [04:21<1:16:55, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch17.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3516 - mse: 0.3514 - mae: 0.4757\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3534 - mse: 0.3532 - mae: 0.4767\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3788 - mse: 0.3786 - mae: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 17/299 [04:37<1:16:23, 16.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch18.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3515 - mse: 0.3513 - mae: 0.4756\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3533 - mse: 0.3531 - mae: 0.4766\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3786 - mse: 0.3784 - mae: 0.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 18/299 [04:53<1:16:03, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to save_models/sp500_20082017-train_train-kS_hyper-epoch19.h5\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2779 - mse: 0.2777 - mae: 0.4213\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3513 - mse: 0.3511 - mae: 0.4755\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3531 - mse: 0.3529 - mae: 0.4766\n",
      "1083/1747 [=================>............] - ETA: 1s - loss: 0.3760 - mse: 0.3758 - mae: 0.4911"
     ]
    }
   ],
   "source": [
    "res_csv_path = res_dir/f'{output_file_name}{lstm_hyper_param}_lstm_evaluation.csv'\n",
    "res_csv_path.touch(exist_ok=True)\n",
    "with open(res_csv_path, 'r+') as f:\n",
    "    if not f.read():\n",
    "        f.write(\"epoch,TRAIN_MSE,DEV_MSE,TEST1_MSE,TEST2_MSE,TRAIN_MAE,DEV_MAE,TEST1_MAE,TEST2_MAE\")\n",
    "\n",
    "res_df = pd.read_csv(res_csv_path)\n",
    "saved_model_list = [int(p.stem[p.stem.find(\"epoch\")+len(\"epoch\"):]) for p in model_dir.glob('*.h5')]\n",
    "epoch_start = max(saved_model_list) if saved_model_list else 1\n",
    "\n",
    "try:\n",
    "    for epoch_num in tqdm(range(epoch_start, max_epoch)):\n",
    "        if epoch_num > 1:\n",
    "            lstm_model = load_model(model_dir/f\"{output_file_name}{lstm_hyper_param}-epoch{epoch_num - 1}.h5\", custom_objects={'double_tanh':double_tanh})\n",
    "\n",
    "        save_model = ModelCheckpoint(model_dir/f\"{output_file_name}{lstm_hyper_param}-epoch{epoch_num}.h5\",\n",
    "                                     monitor='loss', verbose=1, mode='min', save_best_only=False)\n",
    "        lstm_model.fit(lstm_train_X, lstm_train_Y, epochs=1, batch_size=batch_size, callbacks=[model_log, save_model], shuffle=True, verbose=0)\n",
    "\n",
    "        # test the model\n",
    "        score_train = lstm_model.evaluate(lstm_train_X, lstm_train_Y)\n",
    "        score_dev = lstm_model.evaluate(lstm_dev_X, lstm_dev_Y)\n",
    "        score_test1 = lstm_model.evaluate(lstm_test1_X, lstm_test1_Y)\n",
    "        score_test2 = lstm_model.evaluate(lstm_test2_X, lstm_test2_Y)\n",
    "        metrics_mse_ind = lstm_metrics.index('mse') + 1  # need to plus one, because first term of lstm_model.evaluate() is loss\n",
    "        metrics_mae_ind = lstm_metrics.index('mae') + 1  # need to plus one, because first term of lstm_model.evaluate() is loss\n",
    "        res_each_epoch_df = pd.DataFrame(np.array([epoch_num, score_train[metrics_mse_ind], score_dev[metrics_mse_ind],\n",
    "                                                   score_test1[metrics_mse_ind], score_test2[metrics_mse_ind],\n",
    "                                                   score_train[metrics_mae_ind], score_dev[metrics_mae_ind],\n",
    "                                                   score_test1[metrics_mae_ind], score_test2[metrics_mae_ind]]).reshape(-1, 9),\n",
    "                                         columns=[\"epoch\", \"TRAIN_MSE\", \"DEV_MSE\", \"TEST1_MSE\",\n",
    "                                                  \"TEST2_MSE\", \"TRAIN_MAE\", \"DEV_MAE\",\n",
    "                                                  \"TEST1_MAE\", \"TEST2_MAE\"])\n",
    "        res_df = pd.concat([res_df, res_each_epoch_df])\n",
    "        if (res_df.shape[0] % 100) == 0:\n",
    "            res_df.to_csv(res_csv_path, index=False)  # insurance for ãfinallyã part doesent'work\n",
    "except Exception as e:\n",
    "    error_class = e.__class__.__name__  # åå¾é¯èª¤é¡å\n",
    "    detail = e.args[0]  # åå¾è©³ç´°å§å®¹\n",
    "    cl, exc, tb = sys.exc_info()  # åå¾Call Stack\n",
    "    last_call_stack = traceback.extract_tb(tb)[-1]  # åå¾Call Stackçæå¾ä¸ç­è³æ\n",
    "    file_name = last_call_stack[0]  # åå¾ç¼ççæªæ¡åç¨±\n",
    "    line_num = last_call_stack[1]  # åå¾ç¼ççè¡è\n",
    "    func_name = last_call_stack[2]  # åå¾ç¼ççå½æ¸åç¨±\n",
    "    err_msg = \"File \\\"{}\\\", line {}, in {}: [{}] {}\".format(file_name, line_num, func_name, error_class, detail)\n",
    "    logging.error(err_msg)\n",
    "else:\n",
    "    pass\n",
    "finally:\n",
    "    res_df.to_csv(res_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
