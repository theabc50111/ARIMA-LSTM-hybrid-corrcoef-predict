{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41660f84-97c9-4162-a708-f601b3b7a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.06 ms (started: 2022-09-10 03:52:38 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from pmdarima.arima import ARIMA, auto_arima\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "err_log_handler = logging.FileHandler(filename=\"./models/arima_train_err_log.txt\", mode='a')        \n",
    "err_logger = logging.getLogger(\"arima_train_err\")\n",
    "err_logger.addHandler(err_log_handler)\n",
    "\n",
    "# %load_ext pycodestyle_magic\n",
    "# %pycodestyle_on --ignore E501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a012b1-6376-486e-b5dd-93c76929fc3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b48014cb-2099-4e71-b0c5-131dc687387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:len(train_set): 150, len(all_set): 445, len(test_set): 295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms (started: 2022-09-10 03:52:39 +00:00)\n"
     ]
    }
   ],
   "source": [
    "stock_price_df = pd.read_csv(\"../../stock08_price.csv\")\n",
    "\n",
    "# train data\n",
    "portfolio_train = ['CELG', 'PXD', 'WAT', 'LH', 'AMGN', 'AOS', 'EFX', 'CRM', 'NEM', 'JNPR', 'LB', 'CTAS', 'MAT', 'MDLZ', 'VLO', 'APH', 'ADM', 'MLM', 'BK', 'NOV', 'BDX', 'RRC', 'IVZ', 'ED', 'SBUX', 'GRMN', 'CI', 'ZION', 'COO', 'TIF', 'RHT', 'FDX', 'LLL', 'GLW', 'GPN', 'IPGP', 'GPC', 'HPQ', 'ADI', 'AMG', 'MTB', 'YUM', 'SYK', 'KMX', 'AME', 'AAP', 'DAL', 'A', 'MON', 'BRK', 'BMY', 'KMB', 'JPM', 'CCI', 'AET', 'DLTR', 'MGM', 'FL', 'HD', 'CLX', 'OKE', 'UPS', 'WMB', 'IFF', 'CMS', 'ARNC', 'VIAB', 'MMC', 'REG', 'ES', 'ITW', 'NDAQ', 'AIZ', 'VRTX', 'CTL', 'QCOM', 'MSI', 'NKTR', 'AMAT', 'BWA', 'ESRX', 'TXT', 'EXR', 'VNO', 'BBT', 'WDC', 'UAL', 'PVH', 'NOC', 'PCAR', 'NSC', 'UAA', 'FFIV', 'PHM', 'LUV', 'HUM', 'SPG', 'SJM', 'ABT', 'CMG', 'ALK', 'ULTA', 'TMK', 'TAP', 'SCG', 'CAT', 'TMO', 'AES', 'MRK', 'RMD', 'MKC', 'WU', 'ACN', 'HIG', 'TEL', 'DE', 'ATVI', 'O', 'UNM', 'VMC', 'ETFC', 'CMA', 'NRG', 'RHI', 'RE', 'FMC', 'MU', 'CB', 'LNT', 'GE', 'CBS', 'ALGN', 'SNA', 'LLY', 'LEN', 'MAA', 'OMC', 'F', 'APA', 'CDNS', 'SLG', 'HP', 'XLNX', 'SHW', 'AFL', 'STT', 'PAYX', 'AIG', 'FOX', 'MA']\n",
    "# all data\n",
    "portfolio_all = list(stock_price_df.columns.values[1:])\n",
    "portfolio_all.remove(\"SP500\")\n",
    "# all data - train data\n",
    "portfolio_other = [p for p in universe if p not in portfolio_train]\n",
    "logging.info(f\"len(train_set): {len(portfolio_train)}, len(all_set): {len(portfolio_all)}, len(test_set): {len(portfolio_other)}\")\n",
    "# evaluation set\n",
    "train_info = {\"paper_eva_1\": {\"portfolio\": ['PRGO', 'MRO', 'ADP', 'HCP', 'FITB', 'PEG', 'SYMC', 'EOG', 'MDT', 'NI'], \"file_name\": \"paper_eva_1_res\"},\n",
    "            \"paper_eva_2\": {\"portfolio\": ['STI', 'COP', 'MCD', 'AON', 'JBHT', 'DISH', 'GS', 'LRCX', 'CTXS', 'LEG'], \"file_name\": \"paper_eva_2_res\"},\n",
    "            \"paper_eva_3\": {\"portfolio\": ['TJX', 'EMN', 'JCI', 'C', 'BIIB', 'HOG', 'PX', 'PH', 'XEC', 'JEC'], \"file_name\": \"paper_eva_3_res\"},\n",
    "            \"paper_eva_4\": {\"portfolio\": ['ROP', 'AZO', 'URI', 'TROW', 'CMCSA', 'SLB', 'VZ', 'MAC', 'ADS', 'MCK'], \"file_name\": \"paper_eva_4_res\"},\n",
    "            \"paper_eva_5\": {\"portfolio\": ['RL', 'CVX', 'SRE', 'PFE', 'PCG', 'UTX', 'NTRS', 'INCY', 'COP', 'HRL'], \"file_name\": \"paper_eva_5_res\"},\n",
    "            \"445_all\": {\"portfolio\": portfolio_all, \"file_name\": \"sp500_20082017_all_res\"},\n",
    "            \"150_train\": {\"portfolio\": portfolio_train, \"file_name\": \"sp500_20082017_train_res\"},\n",
    "            \"295_test\": {\"portfolio\": portfolio_other, \"file_name\": \"sp500_20082017_test_res\"},\n",
    "           }\n",
    "\n",
    "\n",
    "data_implement = \"150_train\"\n",
    "portfolio_implement = train_info[data_implement]['portfolio']\n",
    "output_file_name = train_info[data_implement]['file_name']\n",
    "fig_title = data_implement\n",
    "\n",
    "# setting of output files\n",
    "save_raw_corr_data = True\n",
    "save_train_info_arima_resid_data = True\n",
    "\n",
    "\n",
    "pd.to_datetime(stock_price_df['Date'], format='%Y-%m-%d')\n",
    "stock_price_df = stock_price_df.set_index(pd.DatetimeIndex(stock_price_df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7765e10-2944-4621-b62f-6602a573387f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11175it [00:26, 421.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.7 s (started: 2022-09-10 03:52:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def gen_data_corr(portfolio: list, corr_ind: list) -> \"pd.DataFrame\":\n",
    "    tmp_corr = stock_price_df[portfolio[0]].rolling(window=100).corr(stock_price_df[portfolio[1]])\n",
    "    tmp_corr = tmp_corr.iloc[corr_ind].values\n",
    "    data_df = pd.DataFrame(tmp_corr.reshape(-1, 24), dtype=\"float32\")\n",
    "    ind = [f\"{portfolio[0]} & {portfolio[1]}_{i}\" for i in range(0, 100, 20)]\n",
    "    data_df.index = ind\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def gen_train_data(portfolio: list, corr_ind: list, save_file: bool = False)-> \"four pd.DataFrame\":\n",
    "    train_df = pd.DataFrame(dtype=\"float32\")\n",
    "    dev_df = pd.DataFrame(dtype=\"float32\")\n",
    "    test1_df = pd.DataFrame(dtype=\"float32\")\n",
    "    test2_df = pd.DataFrame(dtype=\"float32\")\n",
    "\n",
    "    for pair in tqdm(combinations(portfolio, 2)):\n",
    "        data_df = gen_data_corr([pair[0], pair[1]], corr_ind=corr_ind)\n",
    "        data_split = {'train': [0, 21], 'dev': [1, 22], 'test1': [2, 23], 'test2': [3, 24]}\n",
    "        train_df = pd.concat([train_df, data_df.iloc[:, 0:21]])\n",
    "        dev_df = pd.concat([dev_df, data_df.iloc[:, 1:22]])\n",
    "        test1_df = pd.concat([test1_df, data_df.iloc[:, 2:23]])\n",
    "        test2_df = pd.concat([test2_df, data_df.iloc[:, 3:24]])\n",
    "\n",
    "    if save_file:\n",
    "        Path('./dataset/before_arima/').mkdir(parents=True, exist_ok=True)\n",
    "        train_df.to_csv(f\"./dataset/before_arima/{output_file_name}_train.csv\")\n",
    "        dev_df.to_csv(f\"./dataset/before_arima/{output_file_name}_dev.csv\")\n",
    "        test1_df.to_csv(f\"./dataset/before_arima/{output_file_name}_test1.csv\")\n",
    "        test2_df.to_csv(f\"./dataset/before_arima/{output_file_name}_test2.csv\")\n",
    "\n",
    "    return train_df, dev_df, test1_df, test2_df \n",
    "\n",
    "\n",
    "corr_ind = list(range(99, 2400, 100)) + list(range(99+20, 2500, 100)) + list(range(99+40, 2500, 100)) + list(range(99+60, 2500, 100)) + list(range(99+80, 2500, 100))\n",
    "corr_datasets = gen_train_data(portfolio_implement, corr_ind, save_file = save_raw_corr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fe9e2-e6a3-4ce6-8484-7c61691b203d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c7ee34a-a8f6-4609-9e69-cfa66bc19100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 ms (started: 2022-09-10 03:53:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def arima_model(dataset: \"pd.DataFrame\", save_file_period: str = \"\") -> (\"pd.DataFrame\", \"pd.DataFrame\", \"pd.DataFrame\"):\n",
    "    model_110 = ARIMA(order=(1, 1, 0), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_011 = ARIMA(order=(0, 1, 1), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_111 = ARIMA(order=(1, 1, 1), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_211 = ARIMA(order=(2, 1, 1), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    model_210 = ARIMA(order=(2, 1, 0), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "    #model_330 = ARIMA(order=(3, 3, 0), out_of_sample_size=0, mle_regression=True, suppress_warnings=True)\n",
    "\n",
    "    #model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210, \"model_330\": model_330}\n",
    "    model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210}\n",
    "    tested_models = []\n",
    "    arima_model = None\n",
    "    find_arima_model = False\n",
    "    arima_output_list = []\n",
    "    arima_resid_list = []\n",
    "    arima_model_info_list = []\n",
    "    for corr_pair, corr_series in dataset.iterrows():\n",
    "        while not find_arima_model:\n",
    "            try:\n",
    "                for model_key in model_dict:\n",
    "                    if model_key not in tested_models:\n",
    "                        test_model = model_dict[model_key].fit(corr_series[:-1]) # only use first 20 corrletaion coefficient to fit ARIMA model\n",
    "                        if arima_model is None:\n",
    "                            arima_model = test_model\n",
    "                            arima_model_name = model_key\n",
    "                        elif arima_model.aic() <= test_model.aic():\n",
    "                            pass\n",
    "                        else:\n",
    "                            arima_model = test_model\n",
    "                            arima_model_name = model_key\n",
    "                    tested_models.append(model_key)\n",
    "            except Exception:\n",
    "                if len(model_dict)-1 != 0:\n",
    "                    del model_dict[model_key]\n",
    "                else:\n",
    "                    err_logger.error(f\"fatal error, {corr_pair} doesn't have appropriate arima model\\n\", exc_info=True)\n",
    "                    break\n",
    "            else:\n",
    "                #model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210, \"model_330\": model_330}\n",
    "                model_dict = {\"model_110\": model_110, \"model_011\": model_011, \"model_111\": model_111, \"model_211\": model_211, \"model_210\": model_210}\n",
    "                tested_models.clear()\n",
    "                find_arima_model = True\n",
    "        try:\n",
    "            arima_pred = list(arima_model.predict(n_periods=1))\n",
    "        except Exception:\n",
    "            err_logger.error(f\"{corr_pair} in {save_file_period} be predicted by {arima_model_name}(its aic:{arima_model.aic()}) getting error:\\n\", exc_info=True)\n",
    "            dataset = dataset.drop(index=corr_pair)\n",
    "        else:\n",
    "            arima_pred_in_sample = list(arima_model.predict_in_sample())\n",
    "            arima_pred_in_sample = [np.mean(arima_pred_in_sample[1:])] + arima_pred_in_sample[1:]\n",
    "            arima_output = arima_pred_in_sample + arima_pred\n",
    "            arima_output = np.clip(np.array(arima_output), -1, 1)\n",
    "            arima_output_list.append(arima_output)\n",
    "            \n",
    "            arima_resid = pd.Series(np.array(corr_series) - arima_output)\n",
    "            arima_resid_list.append(np.array(arima_resid))\n",
    "            arima_infos = [corr_pair, arima_model_name]\n",
    "            for attr in [\"aic\", \"pvalues\", \"params\", \"arparams\", \"aroots\", \"maparams\", \"maroots\"]:\n",
    "                try:\n",
    "                    val = getattr(arima_model, attr)()\n",
    "                except AttributeError:\n",
    "                    arima_infos.append(None)\n",
    "                else:\n",
    "                    arima_infos.append(val)\n",
    "            else:\n",
    "                arima_model_info_list.append(arima_infos)\n",
    "        finally:\n",
    "            find_arima_model = False\n",
    "\n",
    "\n",
    "    arima_model_info_df = pd.DataFrame(arima_model_info_list, dtype=\"float32\", columns=[\"items\", \"model_name\", \"aic\", \"pvalues\", \"params\", \"arparams\", \"aroots\", \"maparams\", \"maroots\"]).set_index(\"items\")\n",
    "    arima_output_df = pd.DataFrame(arima_output_list, dtype=\"float32\", index=dataset.index)\n",
    "    arima_resid_df = pd.DataFrame(arima_resid_list, dtype=\"float32\", index=dataset.index)\n",
    "\n",
    "    if save_file_period:\n",
    "        Path('./dataset/after_arima').mkdir(parents=True, exist_ok=True)\n",
    "        arima_model_info_df.to_csv(f'./dataset/after_arima/{output_file_name}_arima_model_info_{save_file_period}.csv')\n",
    "        arima_output_df.to_csv(f'./dataset/after_arima/{output_file_name}_arima_output_{save_file_period}.csv')\n",
    "        arima_resid_df.to_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_{save_file_period}.csv')\n",
    "\n",
    "    return arima_output_df, arima_resid_df, arima_model_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a253c7-552c-4c6c-9072-8a6cc83297c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]ERROR:arima_train_err:WAT & JPM_0 in train be predicted by model_211(its aic:10.0) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "ERROR:arima_train_err:NEM & DAL_80 in train be predicted by model_211(its aic:10.0) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "ERROR:arima_train_err:MDLZ & NKTR_40 in train be predicted by model_211(its aic:10.0) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "ERROR:arima_train_err:RHT & CB_60 in train be predicted by model_211(its aic:10.0) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "ERROR:arima_train_err:GLW & LNT_60 in train be predicted by model_211(its aic:10.0) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "ERROR:arima_train_err:BMY & DE_40 in train be predicted by model_211(its aic:10.0) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "ERROR:arima_train_err:ITW & LEN_80 in train be predicted by model_211(its aic:10.0) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "ERROR:arima_train_err:MRK & HP_60 in train be predicted by model_211(its aic:24.947601847121156) getting error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_429/2611628286.py\", line 44, in arima_model\n",
      "    arima_pred = list(arima_model.predict(n_periods=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 793, in predict\n",
      "    f, conf_int = _seasonal_prediction_with_confidence(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pmdarima/arima/arima.py\", line 205, in _seasonal_prediction_with_confidence\n",
      "    conf_int = check_array(conf_int, copy=False, dtype=None)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 899, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n"
     ]
    }
   ],
   "source": [
    "for (file_name, dataset) in tqdm(zip(['train', 'dev', 'test1', 'test2'], corr_datasets)):\n",
    "    if save_train_info_arima_resid_data:\n",
    "        arima_model(dataset, save_file_period=file_name)\n",
    "    else:\n",
    "        arima_model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb455ad-4103-403d-a65f-ba8a13038295",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed36f1c-62c7-4874-a3a4-1aaf35bcdc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 753 ms (started: 2022-09-09 05:54:10 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Dataset.from_tensor_slices(dict(pd.read_csv(f'./dataset/after_arima/arima_resid_train.csv')))\n",
    "lstm_train_X = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_train.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_train_Y = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_train.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_dev_X = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_dev.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_dev_Y = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_dev.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_test1_X = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_test1.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_test1_Y = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_test1.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "lstm_test2_X = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_test2.csv').set_index('Unnamed: 0').iloc[::, :-1]\n",
    "lstm_test2_Y = pd.read_csv(f'./dataset/after_arima/{output_file_name}_arima_resid_test2.csv').set_index('Unnamed: 0').iloc[::, -1]\n",
    "\n",
    "lstm_train_X = lstm_train_X.values.reshape(-1, 20, 1)\n",
    "lstm_train_Y = lstm_train_Y.values.reshape(-1, 1)\n",
    "lstm_dev_X = lstm_dev_X.values.reshape(-1, 20, 1)\n",
    "lstm_dev_Y = lstm_dev_Y.values.reshape(-1, 1)\n",
    "lstm_test1_X = lstm_test1_X.values.reshape(-1, 20, 1)\n",
    "lstm_test1_Y = lstm_test1_Y.values.reshape(-1, 1)\n",
    "lstm_test2_X = lstm_test2_X.values.reshape(-1, 20, 1)\n",
    "lstm_test2_Y = lstm_test2_Y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df49f64-a93a-4104-b07d-dfbd0a688004",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 05:54:12.941454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:12.945384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:12.945601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:12.946360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-09 05:54:12.947364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:12.947575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:12.947747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:13.292361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:13.292527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:13.292655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-09 05:54:13.292749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"many_one_lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 25)                2700      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,726\n",
      "Trainable params: 2,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 749 ms (started: 2022-09-09 05:54:12 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def double_tanh(x):\n",
    "    return (tf.math.tanh(x) *2)\n",
    "\n",
    "\n",
    "def build_many_one_lstm():\n",
    "    inputs = Input(shape=(20, 1))\n",
    "    lstm_1 = LSTM(units=25, kernel_regularizer=l1_l2(0.0, 0.0), bias_regularizer=l1_l2(0.0, 0.0))(inputs)\n",
    "    outputs = Dense(units=1, activation=double_tanh)(lstm_1)\n",
    "    return keras.Model(inputs, outputs, name=\"many_one_lstm\")\n",
    "\n",
    "\n",
    "lstm_model = build_many_one_lstm()\n",
    "lstm_model.summary()\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2b47f-ad31-431f-8ded-1e2acf98d7c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 05:54:23.770500: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/112 [===>..........................] - ETA: 0s - loss: 0.2834 - mse: 0.2834 - mae: 0.4287  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 05:54:24.185315: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/112 [==========================>...] - ETA: 0s - loss: 0.2682 - mse: 0.2682 - mae: 0.4146\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_1.h5\n",
      "112/112 [==============================] - 2s 3ms/step - loss: 0.2674 - mse: 0.2674 - mae: 0.4141\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2612 - mse: 0.2612 - mae: 0.4098\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3187 - mse: 0.3187 - mae: 0.4570\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3315 - mse: 0.3315 - mae: 0.4642\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3555 - mse: 0.3555 - mae: 0.4803\n",
      "104/112 [==========================>...] - ETA: 0s - loss: 0.2486 - mse: 0.2486 - mae: 0.4007\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_2.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2488 - mse: 0.2488 - mae: 0.4008\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2409 - mse: 0.2409 - mae: 0.3991\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3027 - mse: 0.3027 - mae: 0.4478\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3125 - mse: 0.3125 - mae: 0.4549\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3344 - mse: 0.3344 - mae: 0.4697\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2354 - mse: 0.2354 - mae: 0.3917\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_3.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2355 - mse: 0.2355 - mae: 0.3918\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2317 - mse: 0.2317 - mae: 0.3905\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3034 - mse: 0.3034 - mae: 0.4471\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3098 - mse: 0.3098 - mae: 0.4517\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3351 - mse: 0.3351 - mae: 0.4706\n",
      "104/112 [==========================>...] - ETA: 0s - loss: 0.2300 - mse: 0.2300 - mae: 0.3882\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_4.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2304 - mse: 0.2304 - mae: 0.3885\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2285 - mse: 0.2285 - mae: 0.3829\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3100 - mse: 0.3100 - mae: 0.4494\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3152 - mse: 0.3152 - mae: 0.4519\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3460 - mse: 0.3460 - mae: 0.4767\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 0.2279 - mse: 0.2279 - mae: 0.3869\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_5.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2285 - mse: 0.2285 - mae: 0.3873\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2311 - mse: 0.2311 - mae: 0.3818\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3189 - mse: 0.3189 - mae: 0.4541\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3241 - mse: 0.3241 - mae: 0.4559\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3561 - mse: 0.3561 - mae: 0.4819\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.2261 - mse: 0.2261 - mae: 0.3855\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_6.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2261 - mse: 0.2261 - mae: 0.3855\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2251 - mse: 0.2251 - mae: 0.3895\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2895 - mse: 0.2895 - mae: 0.4409\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2969 - mse: 0.2969 - mae: 0.4461\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3234 - mse: 0.3234 - mae: 0.4669\n",
      "104/112 [==========================>...] - ETA: 0s - loss: 0.2253 - mse: 0.2253 - mae: 0.3848\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_7.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2254 - mse: 0.2254 - mae: 0.3851\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2234 - mse: 0.2234 - mae: 0.3867\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2910 - mse: 0.2910 - mae: 0.4416\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2971 - mse: 0.2971 - mae: 0.4454\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3269 - mse: 0.3269 - mae: 0.4688\n",
      "105/112 [===========================>..] - ETA: 0s - loss: 0.2245 - mse: 0.2245 - mae: 0.3845\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_8.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2244 - mse: 0.2244 - mae: 0.3845\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2245 - mse: 0.2245 - mae: 0.3791\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3175 - mse: 0.3175 - mae: 0.4531\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3162 - mse: 0.3162 - mae: 0.4505\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3563 - mse: 0.3563 - mae: 0.4814\n",
      "103/112 [==========================>...] - ETA: 0s - loss: 0.2240 - mse: 0.2240 - mae: 0.3838\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_9.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2238 - mse: 0.2238 - mae: 0.3837\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2212 - mse: 0.2212 - mae: 0.3818\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3013 - mse: 0.3013 - mae: 0.4454\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3042 - mse: 0.3042 - mae: 0.4468\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3386 - mse: 0.3386 - mae: 0.4740\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.2226 - mse: 0.2226 - mae: 0.3831\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_10.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2226 - mse: 0.2226 - mae: 0.3830\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2224 - mse: 0.2224 - mae: 0.3867\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2931 - mse: 0.2931 - mae: 0.4420\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2972 - mse: 0.2972 - mae: 0.4450\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3285 - mse: 0.3285 - mae: 0.4689\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2232 - mse: 0.2232 - mae: 0.3838\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_11.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2228 - mse: 0.2228 - mae: 0.3834\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2211 - mse: 0.2211 - mae: 0.3859\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2904 - mse: 0.2904 - mae: 0.4408\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2962 - mse: 0.2962 - mae: 0.4447\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3275 - mse: 0.3275 - mae: 0.4691\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2211 - mse: 0.2211 - mae: 0.3819\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_12.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2213 - mse: 0.2213 - mae: 0.3821\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2220 - mse: 0.2220 - mae: 0.3765\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3148 - mse: 0.3148 - mae: 0.4512\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3162 - mse: 0.3162 - mae: 0.4504\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3571 - mse: 0.3571 - mae: 0.4829\n",
      "103/112 [==========================>...] - ETA: 0s - loss: 0.2211 - mse: 0.2211 - mae: 0.3818\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_13.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2212 - mse: 0.2212 - mae: 0.3819\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2200 - mse: 0.2200 - mae: 0.3813\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3011 - mse: 0.3011 - mae: 0.4454\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3057 - mse: 0.3057 - mae: 0.4478\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3409 - mse: 0.3409 - mae: 0.4760\n",
      "105/112 [===========================>..] - ETA: 0s - loss: 0.2209 - mse: 0.2209 - mae: 0.3820\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_14.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2209 - mse: 0.2209 - mae: 0.3820\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2192 - mse: 0.2192 - mae: 0.3801\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3029 - mse: 0.3029 - mae: 0.4459\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3049 - mse: 0.3049 - mae: 0.4465\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3426 - mse: 0.3426 - mae: 0.4757\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 0.2212 - mse: 0.2212 - mae: 0.3822\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_15.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2212 - mse: 0.2212 - mae: 0.3821\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2194 - mse: 0.2194 - mae: 0.3821\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3030 - mse: 0.3030 - mae: 0.4462\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3045 - mse: 0.3045 - mae: 0.4472\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3395 - mse: 0.3395 - mae: 0.4742\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.2205 - mse: 0.2205 - mae: 0.3816\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_16.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2202 - mse: 0.2202 - mae: 0.3811\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2186 - mse: 0.2186 - mae: 0.3778\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3080 - mse: 0.3080 - mae: 0.4481\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3084 - mse: 0.3084 - mae: 0.4475\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3495 - mse: 0.3495 - mae: 0.4794\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2196 - mse: 0.2196 - mae: 0.3809\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_17.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2195 - mse: 0.2195 - mae: 0.3808\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2185 - mse: 0.2185 - mae: 0.3791\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2997 - mse: 0.2997 - mae: 0.4445\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3035 - mse: 0.3035 - mae: 0.4461\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3423 - mse: 0.3423 - mae: 0.4765\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.2191 - mse: 0.2191 - mae: 0.3806\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_18.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2189 - mse: 0.2189 - mae: 0.3803\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2212 - mse: 0.2212 - mae: 0.3750\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3179 - mse: 0.3179 - mae: 0.4528\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3190 - mse: 0.3190 - mae: 0.4516\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3632 - mse: 0.3632 - mae: 0.4862\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.2189 - mse: 0.2189 - mae: 0.3805\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_19.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2188 - mse: 0.2188 - mae: 0.3805\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2196 - mse: 0.2196 - mae: 0.3745\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3197 - mse: 0.3197 - mae: 0.4536\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3180 - mse: 0.3180 - mae: 0.4507\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3638 - mse: 0.3638 - mae: 0.4860\n",
      "105/112 [===========================>..] - ETA: 0s - loss: 0.2183 - mse: 0.2183 - mae: 0.3800\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_20.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2185 - mse: 0.2185 - mae: 0.3800\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2185 - mse: 0.2185 - mae: 0.3844\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2884 - mse: 0.2884 - mae: 0.4400\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2939 - mse: 0.2939 - mae: 0.4434\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3292 - mse: 0.3292 - mae: 0.4706\n",
      "105/112 [===========================>..] - ETA: 0s - loss: 0.2185 - mse: 0.2185 - mae: 0.3806\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_21.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2184 - mse: 0.2184 - mae: 0.3802\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2189 - mse: 0.2189 - mae: 0.3860\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2912 - mse: 0.2912 - mae: 0.4415\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2955 - mse: 0.2955 - mae: 0.4450\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3298 - mse: 0.3298 - mae: 0.4716\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.2177 - mse: 0.2177 - mae: 0.3793\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_22.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2181 - mse: 0.2181 - mae: 0.3799\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2187 - mse: 0.2187 - mae: 0.3763\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3041 - mse: 0.3041 - mae: 0.4464\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3072 - mse: 0.3072 - mae: 0.4466\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3506 - mse: 0.3506 - mae: 0.4797\n",
      "104/112 [==========================>...] - ETA: 0s - loss: 0.2191 - mse: 0.2191 - mae: 0.3806\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_23.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2184 - mse: 0.2184 - mae: 0.3803\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2206 - mse: 0.2206 - mae: 0.3745\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3281 - mse: 0.3281 - mae: 0.4580\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3258 - mse: 0.3258 - mae: 0.4551\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3716 - mse: 0.3716 - mae: 0.4905\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.2186 - mse: 0.2186 - mae: 0.3799\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_24.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2185 - mse: 0.2185 - mae: 0.3797\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2194 - mse: 0.2194 - mae: 0.3843\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3006 - mse: 0.3006 - mae: 0.4459\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3047 - mse: 0.3047 - mae: 0.4491\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3400 - mse: 0.3400 - mae: 0.4769\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.2180 - mse: 0.2180 - mae: 0.3795\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_25.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2181 - mse: 0.2181 - mae: 0.3798\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2173 - mse: 0.2173 - mae: 0.3825\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2944 - mse: 0.2944 - mae: 0.4424\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2974 - mse: 0.2974 - mae: 0.4446\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3342 - mse: 0.3342 - mae: 0.4726\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 0.2179 - mse: 0.2179 - mae: 0.3795\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_26.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2180 - mse: 0.2180 - mae: 0.3795\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2171 - mse: 0.2171 - mae: 0.3785\n",
      "1746/1746 [==============================] - 3s 1ms/step - loss: 0.3036 - mse: 0.3036 - mae: 0.4465\n",
      "1746/1746 [==============================] - 3s 1ms/step - loss: 0.3060 - mse: 0.3060 - mae: 0.4475\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3469 - mse: 0.3469 - mae: 0.4790\n",
      "103/112 [==========================>...] - ETA: 0s - loss: 0.2179 - mse: 0.2179 - mae: 0.3795\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_27.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2179 - mse: 0.2179 - mae: 0.3796\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2182 - mse: 0.2182 - mae: 0.3835\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2965 - mse: 0.2965 - mae: 0.4435\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2979 - mse: 0.2979 - mae: 0.4448\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3355 - mse: 0.3355 - mae: 0.4725\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 0.2174 - mse: 0.2174 - mae: 0.3792\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_28.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2177 - mse: 0.2177 - mae: 0.3797\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2197 - mse: 0.2197 - mae: 0.3806\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3182 - mse: 0.3182 - mae: 0.4539\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3128 - mse: 0.3128 - mae: 0.4505\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3563 - mse: 0.3563 - mae: 0.4819\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 0.2180 - mse: 0.2180 - mae: 0.3797\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_29.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2180 - mse: 0.2180 - mae: 0.3796\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2179 - mse: 0.2179 - mae: 0.3788\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3163 - mse: 0.3163 - mae: 0.4527\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3122 - mse: 0.3122 - mae: 0.4500\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3551 - mse: 0.3551 - mae: 0.4815\n",
      "105/112 [===========================>..] - ETA: 0s - loss: 0.2167 - mse: 0.2167 - mae: 0.3789\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_30.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2166 - mse: 0.2166 - mae: 0.3786\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2163 - mse: 0.2163 - mae: 0.3775\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3010 - mse: 0.3010 - mae: 0.4455\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3031 - mse: 0.3031 - mae: 0.4459\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3453 - mse: 0.3453 - mae: 0.4778\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 0.2178 - mse: 0.2178 - mae: 0.3797\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_31.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2173 - mse: 0.2173 - mae: 0.3791\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2173 - mse: 0.2173 - mae: 0.3792\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3013 - mse: 0.3013 - mae: 0.4457\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3013 - mse: 0.3013 - mae: 0.4451\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3446 - mse: 0.3446 - mae: 0.4770\n",
      "102/112 [==========================>...] - ETA: 0s - loss: 0.2175 - mse: 0.2175 - mae: 0.3793\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_32.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2173 - mse: 0.2173 - mae: 0.3790\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2169 - mse: 0.2169 - mae: 0.3754\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3185 - mse: 0.3185 - mae: 0.4534\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3162 - mse: 0.3162 - mae: 0.4514\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3607 - mse: 0.3607 - mae: 0.4849\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.2172 - mse: 0.2172 - mae: 0.3792\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_33.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2173 - mse: 0.2173 - mae: 0.3791\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2180 - mse: 0.2180 - mae: 0.3840\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2879 - mse: 0.2879 - mae: 0.4400\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2925 - mse: 0.2925 - mae: 0.4430\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3300 - mse: 0.3300 - mae: 0.4710\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.2169 - mse: 0.2169 - mae: 0.3789\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_34.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2168 - mse: 0.2168 - mae: 0.3787\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2172 - mse: 0.2172 - mae: 0.3812\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3060 - mse: 0.3060 - mae: 0.4480\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3039 - mse: 0.3039 - mae: 0.4472\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3452 - mse: 0.3452 - mae: 0.4772\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2171 - mse: 0.2171 - mae: 0.3790\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_35.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2172 - mse: 0.2172 - mae: 0.3791\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2182 - mse: 0.2182 - mae: 0.3768\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3064 - mse: 0.3064 - mae: 0.4481\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3061 - mse: 0.3061 - mae: 0.4463\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3531 - mse: 0.3531 - mae: 0.4807\n",
      "101/112 [==========================>...] - ETA: 0s - loss: 0.2175 - mse: 0.2175 - mae: 0.3794\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_36.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2169 - mse: 0.2169 - mae: 0.3787\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2183 - mse: 0.2183 - mae: 0.3822\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3118 - mse: 0.3118 - mae: 0.4510\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3078 - mse: 0.3078 - mae: 0.4494\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3485 - mse: 0.3485 - mae: 0.4786\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2169 - mse: 0.2169 - mae: 0.3789\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_37.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2167 - mse: 0.2167 - mae: 0.3788\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2168 - mse: 0.2168 - mae: 0.3829\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3015 - mse: 0.3015 - mae: 0.4461\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3013 - mse: 0.3013 - mae: 0.4470\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3406 - mse: 0.3406 - mae: 0.4763\n",
      "104/112 [==========================>...] - ETA: 0s - loss: 0.2168 - mse: 0.2168 - mae: 0.3788\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_38.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2169 - mse: 0.2169 - mae: 0.3786\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2200 - mse: 0.2200 - mae: 0.3890\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2876 - mse: 0.2876 - mae: 0.4408\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2935 - mse: 0.2935 - mae: 0.4456\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3278 - mse: 0.3278 - mae: 0.4719\n",
      "104/112 [==========================>...] - ETA: 0s - loss: 0.2169 - mse: 0.2169 - mae: 0.3789\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_39.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2170 - mse: 0.2170 - mae: 0.3789\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2167 - mse: 0.2167 - mae: 0.3823\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2918 - mse: 0.2918 - mae: 0.4419\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2954 - mse: 0.2954 - mae: 0.4444\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3335 - mse: 0.3335 - mae: 0.4730\n",
      "105/112 [===========================>..] - ETA: 0s - loss: 0.2168 - mse: 0.2168 - mae: 0.3789\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_40.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2166 - mse: 0.2166 - mae: 0.3787\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2162 - mse: 0.2162 - mae: 0.3742\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3137 - mse: 0.3137 - mae: 0.4511\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3129 - mse: 0.3129 - mae: 0.4496\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3590 - mse: 0.3590 - mae: 0.4842\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2159 - mse: 0.2159 - mae: 0.3779\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_41.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2162 - mse: 0.2162 - mae: 0.3781\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2164 - mse: 0.2164 - mae: 0.3828\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2933 - mse: 0.2933 - mae: 0.4423\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2960 - mse: 0.2960 - mae: 0.4446\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3342 - mse: 0.3342 - mae: 0.4730\n",
      "103/112 [==========================>...] - ETA: 0s - loss: 0.2162 - mse: 0.2162 - mae: 0.3782\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_42.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2163 - mse: 0.2163 - mae: 0.3783\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2160 - mse: 0.2160 - mae: 0.3780\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3069 - mse: 0.3069 - mae: 0.4485\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3076 - mse: 0.3076 - mae: 0.4489\n",
      "1747/1747 [==============================] - 3s 2ms/step - loss: 0.3500 - mse: 0.3500 - mae: 0.4812\n",
      "103/112 [==========================>...] - ETA: 0s - loss: 0.2168 - mse: 0.2168 - mae: 0.3789\n",
      "Epoch 1: saving model to models/sp500_20082017_train_res_epoch_43.h5\n",
      "112/112 [==============================] - 1s 3ms/step - loss: 0.2163 - mse: 0.2163 - mae: 0.3783\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.2165 - mse: 0.2165 - mae: 0.3798\n",
      "1746/1746 [==============================] - 3s 2ms/step - loss: 0.3017 - mse: 0.3017 - mae: 0.4461\n",
      "1687/1746 [===========================>..] - ETA: 0s - loss: 0.2996 - mse: 0.2996 - mae: 0.4445"
     ]
    }
   ],
   "source": [
    "model_dir = './models'\n",
    "log_dir = './models/lstm_train_logs'\n",
    "res_dir = './results'\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "res_csv_path = Path(res_dir+'/LSTM_evaluation.csv')\n",
    "res_csv_path.touch(exist_ok=True)\n",
    "with open(res_csv_path, 'r+') as f:\n",
    "    if not f.read():\n",
    "        f.write(\"epoch,TRAIN_MSE,DEV_MSE,TEST1_MSE,TEST2_MSE,TRAIN_MAE,DEV_MAE,TEST1_MAE,TEST2_MAE\")\n",
    "\n",
    "res_df = pd.read_csv(res_csv_path)\n",
    "saved_model_list = [int(p.stem.split('_')[1]) for p in Path(model_dir).glob('*.h5')]\n",
    "model_cbk = TensorBoard(log_dir=log_dir)\n",
    "epoch_start = max(saved_model_list) if saved_model_list else 1\n",
    "max_epoch = 500\n",
    "\n",
    "for epoch_num in range(epoch_start, max_epoch):\n",
    "    if epoch_num > 1:\n",
    "        lstm_model = load_model(Path(model_dir)/f\"{output_file_name}_epoch_{epoch_num - 1}.h5\", custom_objects={'double_tanh':double_tanh})\n",
    "\n",
    "    save_model = ModelCheckpoint(Path(model_dir)/f\"{output_file_name}_epoch_{epoch_num}.h5\",\n",
    "                                                 monitor='loss', verbose=1, mode='min', save_best_only=False)\n",
    "    lstm_model.fit(lstm_train_X, lstm_train_Y, epochs=1, batch_size=500, shuffle=True, callbacks=[model_cbk, save_model])\n",
    "    \n",
    "    # test the model\n",
    "    score_train = lstm_model.evaluate(lstm_train_X, lstm_train_Y)\n",
    "    score_dev = lstm_model.evaluate(lstm_dev_X, lstm_dev_Y)\n",
    "    score_test1 = lstm_model.evaluate(lstm_test1_X, lstm_test1_Y)\n",
    "    score_test2 = lstm_model.evaluate(lstm_test2_X, lstm_test2_Y)\n",
    "    res_each_epoch_df = pd.DataFrame(np.array([epoch_num, score_train[0], score_dev[0], \n",
    "                                               score_test1[0], score_test2[0], \n",
    "                                               score_train[1], score_dev[1], \n",
    "                                               score_test1[1], score_test2[1]]).reshape(-1, 9),\n",
    "                                    columns=[\"epoch\", \"TRAIN_MSE\", \"DEV_MSE\", \"TEST1_MSE\", \n",
    "                                             \"TEST2_MSE\", \"TRAIN_MAE\", \"DEV_MAE\",\n",
    "                                             \"TEST1_MAE\",\"TEST2_MAE\"])\n",
    "    res_df = pd.concat([res_df, res_each_epoch_df])\n",
    "\n",
    "res_df.to_csv(res_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bb3d3-1516-4da3-ab8e-f27bd25b0945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
